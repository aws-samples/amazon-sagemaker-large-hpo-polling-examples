{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batching Hyper-parameter Tuning jobs (CPU)\n",
    "\n",
    "In this notebook, we demonstrate how to batch hyper-parameter tuining jobs using a batching strategy valid for both Bayesian and Random Optimization. We will cover both cold and warm start examples using PyTorch.\n",
    "\n",
    "Topics Covered in this notebook:\n",
    "\n",
    "1. SageMaker Hyper-parameter Optimization with PyTorch\n",
    "2. Batching Large-scale HPO jobs\n",
    "\n",
    "Required Infrastructure: We will run this notebook using the PyTorch 1.6 Python 3.6 CPU Optimized kernel.\n",
    "\n",
    "We will use a credit card default dataset from UCI published here: https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients for our example.\n",
    "\n",
    "*Note*: In the code folder, we have also provided files train.py, and train_ray.py which are designed to work on GPU instances. We provide documentation on any other changes you need to make to use GPU instances below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Here you import the necessary libraries we need in order to run the code in the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing deps and restarting kernel\n",
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.6/site-packages (2.23.2)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker) (1.19.1)\n",
      "Requirement already satisfied: boto3>=1.16.32 in /opt/conda/lib/python3.6/site-packages (from sagemaker) (1.16.34)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.6/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.6/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.6/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker) (20.7)\n",
      "Requirement already satisfied: protobuf>=3.1 in /opt/conda/lib/python3.6/site-packages (from sagemaker) (3.14.0)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.6/site-packages (from sagemaker) (20.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker) (3.1.1)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.34 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (1.19.34)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.34->boto3>=1.16.32->sagemaker) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.34->boto3>=1.16.32->sagemaker) (1.25.11)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from google-pasta->sagemaker) (1.15.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->sagemaker) (2.4.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from google-pasta->sagemaker) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /opt/conda/lib/python3.6/site-packages (from sagemaker) (3.14.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from google-pasta->sagemaker) (1.15.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from google-pasta->sagemaker) (1.15.0)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.34 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (1.19.34)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: smdebug in /opt/conda/lib/python3.6/site-packages (1.0.1)\n",
      "Requirement already satisfied: pyinstrument>=3.1.3 in /opt/conda/lib/python3.6/site-packages (from smdebug) (3.2.0)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /opt/conda/lib/python3.6/site-packages (from smdebug) (1.16.34)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.6/site-packages (from smdebug) (3.14.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /opt/conda/lib/python3.6/site-packages (from smdebug) (1.19.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from smdebug) (20.7)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.34 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (1.19.34)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.34->boto3>=1.10.32->smdebug) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.34->boto3>=1.10.32->smdebug) (1.25.11)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->smdebug) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.6.0->smdebug) (1.15.0)\n",
      "Requirement already satisfied: pyinstrument-cext>=0.2.2 in /opt/conda/lib/python3.6/site-packages (from pyinstrument>=3.1.3->smdebug) (0.2.3)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.6.0->smdebug) (1.15.0)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.34 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (1.19.34)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: bokeh in /opt/conda/lib/python3.6/site-packages (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /opt/conda/lib/python3.6/site-packages (from bokeh) (2.11.2)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.6/site-packages (from bokeh) (5.3.1)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /opt/conda/lib/python3.6/site-packages (from bokeh) (8.0.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.6/site-packages (from bokeh) (1.19.1)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.6/site-packages (from bokeh) (20.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from bokeh) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.6/site-packages (from bokeh) (3.7.4.3)\n",
      "Requirement already satisfied: tornado>=5.1 in /opt/conda/lib/python3.6/site-packages (from bokeh) (6.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=2.7->bokeh) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=16.8->bokeh) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.1->bokeh) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting xlrd\n",
      "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 490 kB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: xlrd\n",
      "Successfully installed xlrd-2.0.1\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import IPython\n",
    "install_needed = True  # should only be True once\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install -U sagemaker\n",
    "    !{sys.executable} -m pip install -U smdebug\n",
    "    !{sys.executable} -m pip install -U bokeh\n",
    "    !{sys.executable} -m pip install -U xlrd\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "from time import gmtime, sleep, strftime, time\n",
    "from botocore.config import Config\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from smdebug.profiler.analysis.notebook_utils.timeline_charts import \\\n",
    "    TimelineCharts\n",
    "from smdebug.profiler.analysis.notebook_utils.training_job import TrainingJob\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.debugger import (FrameworkProfile, ProfilerConfig, ProfilerRule,\n",
    "                                Rule, rule_configs)\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.tuner import (CategoricalParameter, ContinuousParameter,\n",
    "                             HyperparameterTuner, IntegerParameter,\n",
    "                             WarmStartConfig, WarmStartTypes)\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region is us-east-1\n"
     ]
    }
   ],
   "source": [
    "sm = boto3.client('sagemaker', config=Config(retries={'max_attempts': 20}))\n",
    "sagemaker_session = sagemaker.Session(sagemaker_client=sm)\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'distributed_hpo/DEMO-pytorch-hpo'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.session.Session().region_name\n",
    "print(f'region is {region}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "For this notebook, we will use a Credit Card Default Dataset published by UCI: https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients. Here we provide the dataset as part of the code in this notebook. \n",
    "\n",
    "This will be sufficient for testing out the SageMaker features above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./data'):\n",
    "    os.mkdir('./data')\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0      20000    2          2         1   24      2      2     -1     -1   \n",
       "1     120000    2          2         2   26     -1      2      0      0   \n",
       "2      90000    2          2         2   34      0      0      0      0   \n",
       "3      50000    2          2         1   37      0      0      0      0   \n",
       "4      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0     -2  ...          0          0          0         0       689         0   \n",
       "1      0  ...       3272       3455       3261         0      1000      1000   \n",
       "2      0  ...      14331      14948      15549      1518      1500      1000   \n",
       "3      0  ...      28314      28959      29547      2000      2019      1200   \n",
       "4      0  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  Default  \n",
       "0         0         0         0        1  \n",
       "1      1000         0      2000        1  \n",
       "2      1000      1000      5000        0  \n",
       "3      1100      1069      1000        0  \n",
       "4      9000       689       679        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel('credit_card_default_data.xls', header=1)\n",
    "df1 = df1.drop(columns = 'ID')\n",
    "#rename the defaults column\n",
    "df1.rename(columns={\"default payment next month\": \"Default\"}, inplace=True)\n",
    "df1.to_csv('./data/data.csv', index=False)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIMIT_BAL    int64\n",
       "SEX          int64\n",
       "EDUCATION    int64\n",
       "MARRIAGE     int64\n",
       "AGE          int64\n",
       "PAY_0        int64\n",
       "PAY_2        int64\n",
       "PAY_3        int64\n",
       "PAY_4        int64\n",
       "PAY_5        int64\n",
       "PAY_6        int64\n",
       "BILL_AMT1    int64\n",
       "BILL_AMT2    int64\n",
       "BILL_AMT3    int64\n",
       "BILL_AMT4    int64\n",
       "BILL_AMT5    int64\n",
       "BILL_AMT6    int64\n",
       "PAY_AMT1     int64\n",
       "PAY_AMT2     int64\n",
       "PAY_AMT3     int64\n",
       "PAY_AMT4     int64\n",
       "PAY_AMT5     int64\n",
       "PAY_AMT6     int64\n",
       "Default      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "\n",
    "In this section we will shuffle and split the data into train and test and explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histgram of the number of defaults versus not\n",
    "df1.Default.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    23364\n",
       "1     6636\n",
       "Name: Default, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Default.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make train folder\n",
    "\n",
    "if not os.path.exists('./train'):\n",
    "    os.mkdir('./train')\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# make test folder \n",
    "\n",
    "if not os.path.exists('./test'):\n",
    "    os.mkdir('./test')\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split\n",
    "\n",
    "Split the raw data into train and test sets. Since the number of foreclosures is very small, we will oversample the training dataset to balance the number of defaulted and non-defaulted loans in the training dataset. Note that this can introduce training/serving skew -- to avoid this, we will prepare a separate test set, derived from the test data which retains the original distribution. The model will be validated against this test set after every training epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(file):\n",
    "    df = pd.read_csv('./data/'+file)\n",
    "    train=df.sample(frac=0.8,random_state=200) #random state is a seed value\n",
    "    test=df.drop(train.index)\n",
    "    print(f'Original training before upsampling shape = ......{train.shape}')\n",
    "    # first upsample the minority class in training dataset\n",
    "    train_majority = train[train.Default==0]\n",
    "    train_minority = train[train.Default==1]\n",
    "    train_minority_upsampled = resample(train_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(train_majority),    # Experiment with this on your own to see if it improves accuracy.\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "    # Combine majority class with upsampled minority class\n",
    "    train_upsampled = pd.concat([train_majority, train_minority_upsampled], axis=0)\n",
    "    train_upsampled=train_upsampled.sample(frac=1) #shuffle the data\n",
    "    print(f\"Train file shape = .....{train_upsampled.shape}\")\n",
    "    print(f\"Test file shape = .....{test.shape}\")\n",
    "    train_upsampled.to_csv(f'./train/{file}', index=False, header=True)\n",
    "    test.to_csv(f'./test/{file}', index=False, header=True)\n",
    "    return len(train_upsampled), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.csv\n",
      "Original training before upsampling shape = ......(24000, 24)\n",
      "Train file shape = .....(37266, 24)\n",
      "Test file shape = .....(6000, 24)\n",
      "Total Training Loans =37266\n",
      "Total Testing Loans = 6000\n"
     ]
    }
   ],
   "source": [
    "total_train_rows = 0\n",
    "total_test_rows = 0\n",
    "for file in os.listdir('./data'): #this will work if you have multiple data files as well. \n",
    "    print(file)\n",
    "    trl, tel = train_test_split(file)\n",
    "    total_test_rows+=tel\n",
    "    total_train_rows+=trl\n",
    "print(f\"Total Training Loans ={total_train_rows}\")\n",
    "print(f\"Total Testing Loans = {total_test_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shard the dataset into smaller files\n",
    "\n",
    "In order for PyTorch to train faster, it is recommended to shard your large dataest into much smaller files. This way the PyTorch dataloader can quickly load one csv at a time consisting of N rows and train the model on that batch. \n",
    "\n",
    "The code below will read in each line from the primary dataframe line by line and store it in a separate dataframe. \n",
    "\n",
    "Then we will repeat this for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./train_full_split'):\n",
    "    os.mkdir('./train_full_split')\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training data into smaller files that can be loaded using the data loader\n",
    "COLS = pd.read_csv('./train/data.csv').columns\n",
    "csvfile = open('./train/data.csv', 'r').readlines()\n",
    "filename = 1\n",
    "for i in range(len(csvfile)):\n",
    "    if i % 10000 == 0:\n",
    "        with open('./train_full_split/' + str(filename) + '.csv', 'w+') as f:\n",
    "            if filename == 1:\n",
    "                f.writelines(csvfile[i:i+10000])\n",
    "            else:\n",
    "                writer = csv.writer(f, delimiter=',')\n",
    "                writer.writerow(COLS)\n",
    "                f.writelines(csvfile[i:i+10000])\n",
    "        filename += 1\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./test_full_split'):\n",
    "    os.mkdir('./test_full_split')\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training data into smaller files that can be loaded using the data loader\n",
    "csvfile = open('./test/data.csv', 'r').readlines()\n",
    "filename = 1\n",
    "for i in range(len(csvfile)):\n",
    "    if i % 10000 == 0:\n",
    "        with open('./test_full_split/' + str(filename) + '.csv', 'w+') as f:\n",
    "            if filename == 1:\n",
    "                f.writelines(csvfile[i:i+10000])\n",
    "            else:\n",
    "                writer = csv.writer(f, delimiter=',')\n",
    "                writer.writerow(COLS)\n",
    "                f.writelines(csvfile[i:i+10000])\n",
    "        filename += 1\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Training and test datasets to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-389535300735/distributed_hpo/DEMO-pytorch-hpo/train\n",
      "s3://sagemaker-us-east-1-389535300735/distributed_hpo/DEMO-pytorch-hpo/test\n"
     ]
    }
   ],
   "source": [
    "#Upload Training and test data into S3\n",
    "train_s3 = sagemaker_session.upload_data(path='./train_full_split/', key_prefix=prefix + '/train')\n",
    "print(train_s3)\n",
    "test_s3 = sagemaker_session.upload_data(path='./test_full_split/', key_prefix=prefix + '/test')\n",
    "print(test_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Script\n",
    "\n",
    "Here we author our training script which we will use for parallel HPO. This train script uses the SageMaker Distributed DataParallel class for PyTorch for distributed training. \n",
    "\n",
    "We will also use SageMaker Profiler to obtain metrics associated with the training job such as the CPU/GPU usage. This is particularly useful for large scale deep learning training jobs.\n",
    "\n",
    "### 1. Create a Training Job with Profiling Enabled<a class=\"anchor\" id=\"option-1\"></a>\n",
    "\n",
    "You will use the standard [SageMaker Estimator API for PyTorch ](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.pytorch.html) to create training jobs. To enable profiling, create a `ProfilerConfig` object and pass it to the `profiler_config` parameter of the `PyTorch` estimator.\n",
    "\n",
    "### 2. Use SM Distributed DataParallel (DDP) to effiently parallelize the training job across multiple GPUs. \n",
    "\n",
    "The training script provides the code you need for distributed data parallel (DDP) training using SMDataParallel. The training script is very similar to a PyTorch training script you might run outside of SageMaker, but modified to run with SMDataParallel. SMDataParallel's PyTorch client provides an alternative to PyTorch's native DDP. For details about how to use SMDataParallel's DDP in your native PyTorch script, see the Getting Started with SMDataParallel tutorials.\n",
    "\n",
    "For your benefit, we have provided 2 training scripts:\n",
    "\n",
    "1. train.py : full training script with SM DDP and SageMaker Profiler\n",
    "\n",
    "2. train_profiler.py : training script with regular PyTorch DDP and SageMaker Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mglob\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mautograd\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mprofiler\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mprofiler\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mdist\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m f1_score, roc_auc_score, roc_curve\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DataLoader, Dataset\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets, transforms\n",
      "\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\n",
      "logger.setLevel(logging.DEBUG)\n",
      "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
      "\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mLoansPredictionDataset\u001b[39;49;00m(Dataset):\n",
      "    \u001b[33m\"\"\"LoanPredictionDataset.\"\"\"\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, root_dir):\n",
      "        \u001b[33m\"\"\"Initializes instance of class LoanPredictionDataset.\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m        Args:\u001b[39;49;00m\n",
      "\u001b[33m            csv_file (str): Path to the csv files with the loan data.\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.paths =  glob.glob(root_dir + \u001b[33m\"\u001b[39;49;00m\u001b[33m/*.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.target = \u001b[33m'\u001b[39;49;00m\u001b[33mDefault\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "        \u001b[37m# Grouping variable names\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__len__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.paths)\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__getitem__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, idx):\n",
      "        data = pd.read_csv(\u001b[36mself\u001b[39;49;00m.paths[idx])\n",
      "        X = data.drop(columns=[\u001b[36mself\u001b[39;49;00m.target], axis=\u001b[34m1\u001b[39;49;00m)\n",
      "        y = data[\u001b[36mself\u001b[39;49;00m.target]\n",
      "        \u001b[34mreturn\u001b[39;49;00m X.values, y.values\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_train_data\u001b[39;49;00m(train_batch_size, dataset, train_sampler, **kwargs):\n",
      "    \u001b[34mreturn\u001b[39;49;00m DataLoader(dataset, batch_size = train_batch_size, shuffle=\u001b[34mFalse\u001b[39;49;00m,\n",
      "                      sampler=train_sampler, **kwargs)\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_test_data\u001b[39;49;00m(test_batch_size, path_to_test_dataset):\n",
      "    dataset = LoansPredictionDataset(path_to_test_dataset)\n",
      "    \u001b[34mreturn\u001b[39;49;00m DataLoader(dataset, batch_size = test_batch_size, shuffle=\u001b[34mFalse\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mNet\u001b[39;49;00m(nn.Module):\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, inp_dimension):\n",
      "        \u001b[36msuper\u001b[39;49;00m().\u001b[32m__init__\u001b[39;49;00m()\n",
      "        \u001b[36mself\u001b[39;49;00m.fc1 = nn.Linear(inp_dimension, \u001b[34m500\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.drop = nn.Dropout(\u001b[34m0.3\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.bn1 = nn.BatchNorm1d(\u001b[34m500\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.bn2=nn.BatchNorm1d(\u001b[34m250\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.fc2 = nn.Linear(\u001b[34m500\u001b[39;49;00m, \u001b[34m250\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.fc3 = nn.Linear(\u001b[34m250\u001b[39;49;00m, \u001b[34m100\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.bn3=nn.BatchNorm1d(\u001b[34m100\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.fc4 = nn.Linear(\u001b[34m100\u001b[39;49;00m,\u001b[34m2\u001b[39;49;00m)\n",
      "        \n",
      "\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\n",
      "        x = x.squeeze()\n",
      "        x = F.relu(\u001b[36mself\u001b[39;49;00m.fc1(x.float()))\n",
      "        x = \u001b[36mself\u001b[39;49;00m.drop(x)\n",
      "        x = \u001b[36mself\u001b[39;49;00m.bn1(x)\n",
      "        x = F.relu(\u001b[36mself\u001b[39;49;00m.fc2(x))\n",
      "        x = \u001b[36mself\u001b[39;49;00m.drop(x)\n",
      "        x = \u001b[36mself\u001b[39;49;00m.bn2(x)\n",
      "        x = F.relu(\u001b[36mself\u001b[39;49;00m.fc3(x))\n",
      "        x = \u001b[36mself\u001b[39;49;00m.drop(x)\n",
      "        x = \u001b[36mself\u001b[39;49;00m.bn3(x)\n",
      "        x = \u001b[36mself\u001b[39;49;00m.fc4(x)\n",
      "        \u001b[37m# last layer converts it to binary classification probability\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m F.log_softmax(x, dim=\u001b[34m1\u001b[39;49;00m)\n",
      "\n",
      "        \n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(args):\n",
      "    is_distributed = \u001b[36mlen\u001b[39;49;00m(args.hosts) > \u001b[34m1\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m args.backend \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mDistributed training - \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(is_distributed))\n",
      "    use_cuda = args.num_gpus > \u001b[34m0\u001b[39;49;00m\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mNumber of gpus available - \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(args.num_gpus))\n",
      "    kwargs = {\u001b[33m'\u001b[39;49;00m\u001b[33mnum_workers\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[34m1\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mpin_memory\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[34mTrue\u001b[39;49;00m} \u001b[34mif\u001b[39;49;00m use_cuda \u001b[34melse\u001b[39;49;00m {}\n",
      "        \n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m use_cuda \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[34mif\u001b[39;49;00m is_distributed:\n",
      "        \u001b[37m# Initialize the distributed environment.\u001b[39;49;00m\n",
      "        world_size = \u001b[36mlen\u001b[39;49;00m(args.hosts)\n",
      "        os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mWORLD_SIZE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[36mstr\u001b[39;49;00m(world_size)\n",
      "        host_rank = args.hosts.index(args.current_host)\n",
      "        os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mRANK\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[36mstr\u001b[39;49;00m(host_rank)\n",
      "        dist.init_process_group(backend=args.backend, rank=host_rank, world_size=world_size)\n",
      "        logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mInitialized the distributed environment: \u001b[39;49;00m\u001b[33m\\'\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\'\u001b[39;49;00m\u001b[33m backend on \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m nodes. \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\n",
      "            args.backend, dist.get_world_size()) + \u001b[33m'\u001b[39;49;00m\u001b[33mCurrent host rank is \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m. Number of gpus: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\n",
      "            dist.get_rank(), args.num_gpus))\n",
      "\n",
      "    \u001b[37m# set the seed for generating random numbers\u001b[39;49;00m\n",
      "    torch.manual_seed(args.seed)\n",
      "    \u001b[34mif\u001b[39;49;00m use_cuda:\n",
      "        torch.cuda.manual_seed(args.seed)\n",
      "    \n",
      "    train_dataset = LoansPredictionDataset(args.data_dir)\n",
      "    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset) \u001b[34mif\u001b[39;49;00m is_distributed \u001b[34melse\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m\n",
      "\n",
      "    train_loader = _get_train_data(args.batch_size, train_dataset, shuffle=train_sampler \u001b[35mis\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m,\n",
      "                                   sampler = train_sampler, **kwargs)\n",
      "\n",
      "\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mProcesses \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m) of train data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "        \u001b[36mlen\u001b[39;49;00m(train_loader.sampler), \u001b[36mlen\u001b[39;49;00m(train_loader.dataset),\n",
      "        \u001b[34m100.\u001b[39;49;00m * \u001b[36mlen\u001b[39;49;00m(train_loader.sampler) / \u001b[36mlen\u001b[39;49;00m(train_loader.dataset)\n",
      "    ))\n",
      "\n",
      "    \n",
      "    \n",
      "    model = Net(args.inp_dimension).to(device)\n",
      "    \u001b[34mif\u001b[39;49;00m is_distributed \u001b[35mand\u001b[39;49;00m use_cuda:\n",
      "        \u001b[37m# multi-machine multi-gpu case\u001b[39;49;00m\n",
      "        model = torch.nn.parallel.DistributedDataParallel(model)\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        \u001b[37m# single-machine multi-gpu case or single-machine or multi-machine cpu case\u001b[39;49;00m\n",
      "        model = torch.nn.DataParallel(model)\n",
      "\n",
      "    loss_optim = nn.CrossEntropyLoss()\n",
      "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
      "\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m, args.epochs + \u001b[34m1\u001b[39;49;00m):\n",
      "        model.train()\n",
      "        \u001b[34mfor\u001b[39;49;00m batch_idx, (data, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_loader):\n",
      "            data, target = data.to(device), target.to(device)\n",
      "            optimizer.zero_grad()\n",
      "            output = model(data)\n",
      "            loss = loss_optim(output, target.squeeze())\n",
      "            loss.backward()\n",
      "            optimizer.step()\n",
      "            \u001b[34mif\u001b[39;49;00m batch_idx % args.log_interval == \u001b[34m0\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m args.rank==\u001b[34m0\u001b[39;49;00m:\n",
      "                logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mTrain Epoch: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m [\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m)] Train Loss: \u001b[39;49;00m\u001b[33m{:.6f}\u001b[39;49;00m\u001b[33m;\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\n",
      "                    epoch, batch_idx * \u001b[36mlen\u001b[39;49;00m(data) * args.world_size, \u001b[36mlen\u001b[39;49;00m(train_loader.dataset),\n",
      "                    \u001b[34m100.\u001b[39;49;00m * batch_idx / \u001b[36mlen\u001b[39;49;00m(train_loader), loss.item()))\n",
      "            \n",
      "        test_loader = _get_test_data(args.test_batch_size, args.test_dir)\n",
      "        logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mProcesses \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m) of test data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "                    \u001b[36mlen\u001b[39;49;00m(test_loader.sampler), \u001b[36mlen\u001b[39;49;00m(test_loader.dataset),\n",
      "                    \u001b[34m100.\u001b[39;49;00m * \u001b[36mlen\u001b[39;49;00m(test_loader.sampler) / \u001b[36mlen\u001b[39;49;00m(test_loader.dataset)))\n",
      "        test(model, test_loader, device, loss_optim)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33msaving the model...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    save_model(model, args.model_dir)\n",
      "                \n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtest\u001b[39;49;00m(model, test_loader, device, loss_optim):\n",
      "    model.eval()\n",
      "    test_loss = \u001b[34m0\u001b[39;49;00m\n",
      "    correct = \u001b[34m0\u001b[39;49;00m\n",
      "    fulloutputs = []\n",
      "    fulltargets = []\n",
      "    fullpreds = []\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\n",
      "        \u001b[34mfor\u001b[39;49;00m i, (data, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(test_loader):\n",
      "            data, target = data.to(device), target.to(device)\n",
      "            output = model(data)\n",
      "            target = target.squeeze()\n",
      "            test_loss += loss_optim(output, target).item()  \u001b[37m# sum up batch loss\u001b[39;49;00m\n",
      "            pred = output.max(\u001b[34m1\u001b[39;49;00m, keepdim=\u001b[34mTrue\u001b[39;49;00m)[\u001b[34m1\u001b[39;49;00m]  \u001b[37m# get the index of the max log-probability\u001b[39;49;00m\n",
      "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
      "            fulloutputs.append(output.cpu().numpy()[:, \u001b[34m1\u001b[39;49;00m])\n",
      "            fulltargets.append(target.cpu().numpy())\n",
      "            fullpreds.append(pred.squeeze().cpu())\n",
      "\n",
      "    i+=\u001b[34m1\u001b[39;49;00m\n",
      "    test_loss /= i\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mTest set Average loss: \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m, Test Accuracy: \u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m;\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\n",
      "            test_loss, \u001b[34m100.\u001b[39;49;00m * correct / (\u001b[36mlen\u001b[39;49;00m(target)*i)\n",
      "        ))\n",
      "    fulloutputs = [item \u001b[34mfor\u001b[39;49;00m sublist \u001b[35min\u001b[39;49;00m fulloutputs \u001b[34mfor\u001b[39;49;00m item \u001b[35min\u001b[39;49;00m sublist]\n",
      "    fulltargets = [item \u001b[34mfor\u001b[39;49;00m sublist \u001b[35min\u001b[39;49;00m fulltargets \u001b[34mfor\u001b[39;49;00m item \u001b[35min\u001b[39;49;00m sublist]\n",
      "    fullpreds = [item \u001b[34mfor\u001b[39;49;00m sublist \u001b[35min\u001b[39;49;00m fullpreds \u001b[34mfor\u001b[39;49;00m item \u001b[35min\u001b[39;49;00m sublist]\n",
      "    logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mTest set F1-score: \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m, Test set AUC: \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\n",
      "        f1_score(fulltargets, fullpreds), roc_auc_score(fulltargets, fulloutputs)))\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_model\u001b[39;49;00m(model, model_dir):\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        torch.save(model.module.state_dict(), f)\n",
      "    \n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# Data and model checkpoints directories\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput batch size for training (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--test-batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput batch size for testing (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 10)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.01\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mlearning rate (default: 0.01)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--momentum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.5\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mSGD momentum (default: 0.5)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--log-interval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mhow many batches to wait before logging training status\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--backend\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[34mNone\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mbackend for distributed training (tcp, gloo on cpu and gloo, nccl on gpu)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--inp-dimension\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m23\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput dimension (number of columns) in training dataset\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--verbose\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, action=\u001b[33m'\u001b[39;49;00m\u001b[33mstore_true\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, default=\u001b[34mFalse\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mFor displaying SMDataParallel-specific logs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Container environment\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--test-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TESTING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--num-gpus\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[37m# start training\u001b[39;49;00m\n",
      "    args = parser.parse_args()\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mStarting training...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    train(args)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize code/train_cpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model. \n",
    "\n",
    "To train the model, we will now use 2 GPUs and also use SageMaker Profiler Capability to generate a report of the GPU utilization, and other performance metrics.\n",
    "\n",
    "#### Estimator function options\n",
    "In the following code block, you can update the estimator function to use a different instance type, instance count, and distrubtion strategy. You're also passing in the training script you reviewed in the previous cell.\n",
    "\n",
    "**Instance types**\n",
    "\n",
    "SMDataParallel supports model training on SageMaker with the following instance types only:\n",
    "ml.p3.16xlarge\n",
    "ml.p3dn.24xlarge [Recommended]\n",
    "ml.p4d.24xlarge [Recommended]\n",
    "\n",
    "**Instance count**\n",
    "To get the best performance and the most out of SMDataParallel, you should use at least 2 instances, but you can also use 1 for testing this example.\n",
    "Distribution strategy\n",
    "Note that to use DDP mode, you update the the distribution strategy, and set it to use smdistributed dataparallel.\n",
    "\n",
    "**Code folder**\n",
    "\n",
    "In order to run SM DistributedDataParallel, we need to ensure our training container has the latest version of the SageMaker SDK. To do this, simply pass in a requirements.txt file along with your code script in the code folder as provided here. We pass in the code folder as the source directory, pointing to the training script. \n",
    "\n",
    "**SageMaker Experiments**\n",
    "\n",
    "We will also track the training jobs using SageMaker Experiments, which will allow data scientist to compare different trials, analyze and extract any metadata from their training runs and compare jobs.\n",
    "\n",
    "This is particularly useful with HPO, when data scientists want to compare different Hyperparameter tuning jobs against one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7fb52a669160>,experiment_name='Classifying-housing-loans-1610551033',description='Classification of loans as default or not',tags=None,experiment_arn='arn:aws:sagemaker:us-east-1:389535300735:experiment/classifying-housing-loans-1610551033',response_metadata={'RequestId': '5737d0ff-c572-4469-af8b-5a26df1d5ce7', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '5737d0ff-c572-4469-af8b-5a26df1d5ce7', 'content-type': 'application/x-amz-json-1.1', 'content-length': '108', 'date': 'Wed, 13 Jan 2021 15:17:13 GMT'}, 'RetryAttempts': 0})\n"
     ]
    }
   ],
   "source": [
    "loan_class_experiment = Experiment.create(\n",
    "    experiment_name=f\"Classifying-housing-loans-{int(time())}\",\n",
    "    description=\"Classification of loans as default or not\", \n",
    "    sagemaker_boto_client=sm)\n",
    "print(loan_class_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2021-01-13-16-04-12-404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-13 16:04:12 Starting - Starting the training job...\n",
      "2021-01-13 16:04:37 Starting - Launching requested ML instancesProfilerReport-1610553852: InProgress\n",
      "......\n",
      "2021-01-13 16:05:38 Starting - Preparing the instances for training...\n",
      "2021-01-13 16:06:12 Downloading - Downloading input data......\n",
      "2021-01-13 16:07:04 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-01-13 16:07:05,123 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-01-13 16:07:05,126 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-01-13 16:07:05,135 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-01-13 16:07:05,142 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-01-13 16:07:19,717 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting sagemaker==2.19.0\n",
      "  Downloading sagemaker-2.19.0.tar.gz (395 kB)\u001b[0m\n",
      "\u001b[34mCollecting ray[tune]\n",
      "  Downloading ray-1.1.0-cp36-cp36m-manylinux2014_x86_64.whl (48.5 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tabulate in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (0.8.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.19.0->-r requirements.txt (line 1)) (20.3.0)\u001b[0m\n",
      "\u001b[34mCollecting boto3>=1.16.32\n",
      "  Downloading boto3-1.16.53-py2.py3-none-any.whl (130 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.19.0->-r requirements.txt (line 1)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.19.0->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.1 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.19.0->-r requirements.txt (line 1)) (3.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.19.0->-r requirements.txt (line 1)) (0.1.5)\u001b[0m\n",
      "\u001b[34mCollecting smdebug_rulesconfig>=1.0.0\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=1.4.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.19.0->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.19.0->-r requirements.txt (line 1)) (20.4)\u001b[0m\n",
      "\u001b[34mCollecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from ray[tune]->-r requirements.txt (line 2)) (5.3.1)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp-cors\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.6/site-packages (from ray[tune]->-r requirements.txt (line 2)) (7.1.2)\u001b[0m\n",
      "\u001b[34mCollecting redis>=3.5.0\n",
      "  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: colorama in /opt/conda/lib/python3.6/site-packages (from ray[tune]->-r requirements.txt (line 2)) (0.4.3)\u001b[0m\n",
      "\u001b[34mCollecting py-spy>=0.2.0\n",
      "  Downloading py_spy-0.3.3-py2.py3-none-manylinux1_x86_64.whl (2.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting opencensus\n",
      "  Downloading opencensus-0.7.11-py2.py3-none-any.whl (127 kB)\u001b[0m\n",
      "\u001b[34mCollecting prometheus-client>=0.7.1\n",
      "  Downloading prometheus_client-0.9.0-py2.py3-none-any.whl (53 kB)\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.28.1\n",
      "  Downloading grpcio-1.34.0-cp36-cp36m-manylinux2014_x86_64.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from ray[tune]->-r requirements.txt (line 2)) (2.24.0)\u001b[0m\n",
      "\u001b[34mCollecting jsonschema\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.6/site-packages (from ray[tune]->-r requirements.txt (line 2)) (3.7.3)\u001b[0m\n",
      "\u001b[34mCollecting msgpack<2.0.0,>=1.0.0\n",
      "  Downloading msgpack-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (272 kB)\u001b[0m\n",
      "\u001b[34mCollecting aioredis\n",
      "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[34mCollecting colorful\n",
      "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\u001b[0m\n",
      "\u001b[34mCollecting gpustat\n",
      "  Downloading gpustat-0.6.0.tar.gz (78 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboardX; extra == \"tune\"\n",
      "  Downloading tensorboardX-2.1-py2.py3-none-any.whl (308 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas; extra == \"tune\" in /opt/conda/lib/python3.6/site-packages (from ray[tune]->-r requirements.txt (line 2)) (1.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses; python_version < \"3.7\" and extra == \"tune\" in /opt/conda/lib/python3.6/site-packages (from ray[tune]->-r requirements.txt (line 2)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker==2.19.0->-r requirements.txt (line 1)) (0.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker==2.19.0->-r requirements.txt (line 1)) (0.10.0)\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.20.0,>=1.19.53\n",
      "  Downloading botocore-1.19.53-py2.py3-none-any.whl (7.2 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from google-pasta->sagemaker==2.19.0->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker==2.19.0->-r requirements.txt (line 1)) (3.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->sagemaker==2.19.0->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mCollecting google-api-core<2.0.0,>=1.0.0\n",
      "  Downloading google_api_core-1.24.1-py2.py3-none-any.whl (92 kB)\u001b[0m\n",
      "\u001b[34mCollecting opencensus-context==0.1.2\n",
      "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->ray[tune]->-r requirements.txt (line 2)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->ray[tune]->-r requirements.txt (line 2)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->ray[tune]->-r requirements.txt (line 2)) (2020.11.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->ray[tune]->-r requirements.txt (line 2)) (1.25.11)\u001b[0m\n",
      "\u001b[34mCollecting pyrsistent>=0.14.0\n",
      "  Downloading pyrsistent-0.17.3.tar.gz (106 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from jsonschema->ray[tune]->-r requirements.txt (line 2)) (50.3.0.post20201006)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.6.5 in /opt/conda/lib/python3.6/site-packages (from aiohttp->ray[tune]->-r requirements.txt (line 2)) (3.7.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /opt/conda/lib/python3.6/site-packages (from aiohttp->ray[tune]->-r requirements.txt (line 2)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp->ray[tune]->-r requirements.txt (line 2)) (3.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.6/site-packages (from aiohttp->ray[tune]->-r requirements.txt (line 2)) (5.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp->ray[tune]->-r requirements.txt (line 2)) (1.6.3)\u001b[0m\n",
      "\u001b[34mCollecting hiredis\n",
      "  Downloading hiredis-1.1.0-cp36-cp36m-manylinux2010_x86_64.whl (61 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /opt/conda/lib/python3.6/site-packages (from gpustat->ray[tune]->-r requirements.txt (line 2)) (7.352.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.6/site-packages (from gpustat->ray[tune]->-r requirements.txt (line 2)) (5.6.7)\u001b[0m\n",
      "\u001b[34mCollecting blessings>=1.6\n",
      "  Downloading blessings-1.7-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas; extra == \"tune\"->ray[tune]->-r requirements.txt (line 2)) (2020.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas; extra == \"tune\"->ray[tune]->-r requirements.txt (line 2)) (2.8.1)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<2.0dev,>=1.21.1\n",
      "  Downloading google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\u001b[0m\n",
      "\u001b[34mCollecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\u001b[0m\n",
      "\u001b[34mCollecting contextvars; python_version >= \"3.6\" and python_version < \"3.7\"\n",
      "  Downloading contextvars-2.4.tar.gz (9.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /opt/conda/lib/python3.6/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]->-r requirements.txt (line 2)) (4.5)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.0-py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting immutables>=0.9\n",
      "  Downloading immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]->-r requirements.txt (line 2)) (0.4.8)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sagemaker, gpustat, pyrsistent, contextvars\n",
      "  Building wheel for sagemaker (setup.py): started\n",
      "  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.19.0-py2.py3-none-any.whl size=553631 sha256=be6a71bc2078ab92dbc29ca4f3db5add2322a92056ac336421e42b7ab027cfb0\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/5f/a2/ae75ce6341001c1605ccc4675808a04f5eb1d0b441ffec4b88\n",
      "  Building wheel for gpustat (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for gpustat (setup.py): finished with status 'done'\n",
      "  Created wheel for gpustat: filename=gpustat-0.6.0-py3-none-any.whl size=12617 sha256=46130068adf304f07590dc49812bb699c91c17934293d6fd819cab04185f6062\n",
      "  Stored in directory: /root/.cache/pip/wheels/50/da/35/fe2cfb3bc47822299f5e124a599d56f00b30ec0b328db16b9f\n",
      "  Building wheel for pyrsistent (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for pyrsistent (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrsistent: filename=pyrsistent-0.17.3-cp36-cp36m-linux_x86_64.whl size=112545 sha256=8e4aad887158a36f151c86deff539bff612b502912e8278a9c25549e7dc376fd\n",
      "  Stored in directory: /root/.cache/pip/wheels/34/13/19/294da8e11bce7e563afee51251b9fa878185e14f4b5caf00cb\n",
      "  Building wheel for contextvars (setup.py): started\n",
      "  Building wheel for contextvars (setup.py): finished with status 'done'\n",
      "  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7665 sha256=67a8d87e551a59f5da49ea08053eb2abef4b84de3af4723c2d143d77e7f7de08\n",
      "  Stored in directory: /root/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\u001b[0m\n",
      "\u001b[34mSuccessfully built sagemaker gpustat pyrsistent contextvars\u001b[0m\n",
      "\u001b[34mInstalling collected packages: botocore, boto3, smdebug-rulesconfig, sagemaker, filelock, aiohttp-cors, redis, py-spy, pyasn1-modules, cachetools, google-auth, googleapis-common-protos, google-api-core, immutables, contextvars, opencensus-context, opencensus, prometheus-client, grpcio, pyrsistent, jsonschema, msgpack, hiredis, aioredis, colorful, blessings, gpustat, tensorboardX, ray\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.19.19\n",
      "    Uninstalling botocore-1.19.19:\n",
      "      Successfully uninstalled botocore-1.19.19\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.16.19\n",
      "    Uninstalling boto3-1.16.19:\n",
      "      Successfully uninstalled boto3-1.16.19\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: smdebug-rulesconfig\n",
      "    Found existing installation: smdebug-rulesconfig 0.1.6\n",
      "    Uninstalling smdebug-rulesconfig-0.1.6:\n",
      "      Successfully uninstalled smdebug-rulesconfig-0.1.6\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.16.4.dev0\n",
      "    Uninstalling sagemaker-2.16.4.dev0:\n",
      "      Successfully uninstalled sagemaker-2.16.4.dev0\u001b[0m\n",
      "\u001b[34mSuccessfully installed aiohttp-cors-0.7.0 aioredis-1.3.1 blessings-1.7 boto3-1.16.53 botocore-1.19.53 cachetools-4.2.0 colorful-0.5.4 contextvars-2.4 filelock-3.0.12 google-api-core-1.24.1 google-auth-1.24.0 googleapis-common-protos-1.52.0 gpustat-0.6.0 grpcio-1.34.0 hiredis-1.1.0 immutables-0.14 jsonschema-3.2.0 msgpack-1.0.2 opencensus-0.7.11 opencensus-context-0.1.2 prometheus-client-0.9.0 py-spy-0.3.3 pyasn1-modules-0.2.8 pyrsistent-0.17.3 ray-1.1.0 redis-3.5.3 sagemaker-2.19.0 smdebug-rulesconfig-1.0.1 tensorboardX-2.1\u001b[0m\n",
      "\u001b[34m2021-01-13 16:07:35,577 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-01-13 16:07:35,589 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-01-13 16:07:35,600 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-01-13 16:07:35,610 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"testing\": \"/opt/ml/input/data/testing\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 3\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"testing\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2021-01-13-16-04-12-404\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-389535300735/pytorch-training-2021-01-13-16-04-12-404/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_cpu\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_cpu.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"epochs\":3}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_cpu.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"testing\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_cpu\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-389535300735/pytorch-training-2021-01-13-16-04-12-404/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":3},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2021-01-13-16-04-12-404\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-389535300735/pytorch-training-2021-01-13-16-04-12-404/source/sourcedir.tar.gz\",\"module_name\":\"train_cpu\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_cpu.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"3\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TESTING=/opt/ml/input/data/testing\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=3\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train_cpu.py --backend gloo --epochs 3\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mStarting training...\u001b[0m\n",
      "\u001b[34mDistributed training - False\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34mProcesses 4/4 (100%) of train data\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.556 algo-1:70 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.695 algo-1:70 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.695 algo-1:70 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.695 algo-1:70 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.696 algo-1:70 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.696 algo-1:70 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.739 algo-1:70 INFO hook.py:550] name:module.fc1.weight count_params:11500\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.739 algo-1:70 INFO hook.py:550] name:module.fc1.bias count_params:500\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.739 algo-1:70 INFO hook.py:550] name:module.bn1.weight count_params:500\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.739 algo-1:70 INFO hook.py:550] name:module.bn1.bias count_params:500\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.739 algo-1:70 INFO hook.py:550] name:module.bn2.weight count_params:250\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.739 algo-1:70 INFO hook.py:550] name:module.bn2.bias count_params:250\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.739 algo-1:70 INFO hook.py:550] name:module.fc2.weight count_params:125000\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.739 algo-1:70 INFO hook.py:550] name:module.fc2.bias count_params:250\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.739 algo-1:70 INFO hook.py:550] name:module.fc3.weight count_params:25000\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.739 algo-1:70 INFO hook.py:550] name:module.fc3.bias count_params:100\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.740 algo-1:70 INFO hook.py:550] name:module.bn3.weight count_params:100\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.740 algo-1:70 INFO hook.py:550] name:module.bn3.bias count_params:100\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.740 algo-1:70 INFO hook.py:550] name:module.fc4.weight count_params:200\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.740 algo-1:70 INFO hook.py:550] name:module.fc4.bias count_params:2\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.740 algo-1:70 INFO hook.py:552] Total Trainable Params: 164252\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.740 algo-1:70 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-01-13 16:07:38.744 algo-1:70 INFO hook.py:476] Hook is writing from the hook with pid: 70\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [0/4 (0%)] Train Loss: 0.741811;\u001b[0m\n",
      "\u001b[34mProcesses 1/1 (100%) of test data\u001b[0m\n",
      "\u001b[34mTest set Average loss: 0.6564, Test Accuracy: 68%;\n",
      "\u001b[0m\n",
      "\u001b[34mTest set F1-score: 0.3215, Test set AUC: 0.6027 \n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [0/4 (0%)] Train Loss: 0.725345;\u001b[0m\n",
      "\u001b[34mProcesses 1/1 (100%) of test data\u001b[0m\n",
      "\u001b[34mTest set Average loss: 0.6883, Test Accuracy: 60%;\n",
      "\u001b[0m\n",
      "\u001b[34mTest set F1-score: 0.3810, Test set AUC: 0.6123 \n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [0/4 (0%)] Train Loss: 0.720291;\u001b[0m\n",
      "\u001b[34mProcesses 1/1 (100%) of test data\u001b[0m\n",
      "\u001b[34mTest set Average loss: 0.7130, Test Accuracy: 56%;\n",
      "\u001b[0m\n",
      "\u001b[34mTest set F1-score: 0.3850, Test set AUC: 0.6204 \n",
      "\u001b[0m\n",
      "\u001b[34msaving the model...\u001b[0m\n",
      "\u001b[34m2021-01-13 16:07:43,569 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-01-13 16:08:00 Uploading - Uploading generated training model\n",
      "2021-01-13 16:08:00 Completed - Training job completed\n",
      "Training seconds: 102\n",
      "Billable seconds: 102\n"
     ]
    }
   ],
   "source": [
    "# Now let's launch a SageMaker training job on  p3 instance. Next we will run a HPO job.\n",
    "trial_name = f\"loan-trial-base-{int(time())}\"\n",
    "loan_trial = Trial.create(\n",
    "        trial_name=trial_name,\n",
    "        experiment_name=loan_class_experiment.experiment_name,\n",
    "        sagemaker_boto_client=sm,\n",
    "    )\n",
    "\n",
    "estimator = PyTorch(entry_point=\"train_cpu.py\", \n",
    "                    role=role,\n",
    "                    framework_version='1.6.0',\n",
    "                    py_version='py36',\n",
    "                    source_dir='./code',\n",
    "                    output_path = f's3://{bucket}/{prefix}/output',\n",
    "                    instance_count=1, \n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    instance_type='ml.m5.xlarge', \n",
    "                    hyperparameters={\n",
    "                        'epochs': 3,\n",
    "                        'backend': 'gloo' #gloo for CPU, nccl for GPU\n",
    "                    },\n",
    "                  # allows Experiments to capture metrics  \n",
    "                    metric_definitions=[\n",
    "                        {'Name':'train:loss', 'Regex':'Train Loss: (.*?);'},\n",
    "                        {'Name':'test:loss', 'Regex':'Test set Average loss: (.*?),'},\n",
    "                        {'Name':'test:accuracy', 'Regex':'Test Accuracy: (.*?)%;'},\n",
    "                        {'Name':'test:F1', 'Regex':'Test set F1-score: (.*?),'}\n",
    "                    ]\n",
    "            )\n",
    "\n",
    "# this is a fire and forget event -- this way you can continue to use the notebook below for other data exploration\n",
    "# and prototyping activities. \n",
    "\n",
    "estimator.fit({'training': train_s3,\n",
    "                'testing':test_s3},\n",
    "              experiment_config={\n",
    "            \"TrialName\": loan_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": \"Training\",\n",
    "        },\n",
    "             wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training job on a GPU\n",
    "\n",
    "To test this estimator out with the latest smdistributed library, make the following changes:\n",
    "\n",
    "1. replace entry_point = \"train.py\"\n",
    "\n",
    "2. add the following code in \"\" after metric_definitions: \"distribution={'smdistributed':{\n",
    "                                            'dataparallel':{\n",
    "                                                    'enabled': True\n",
    "                                                 }\n",
    "                                          }\n",
    "                                     },\"\n",
    " \n",
    " \n",
    "3. In hyperparameters, replace 'backend': 'nccl'\n",
    "\n",
    "This will instantiate the sm distributed library on the containers. To learn more about Sm distributed, see this link: \n",
    "https://aws.amazon.com/sagemaker/distributed-training/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm metrics\n",
    "\n",
    "We want to extract the model metrics on the test set. To do this, we will use the SageMaker Experiments API and extract the metric for the trail above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>SourceArn</th>\n",
       "      <th>SageMaker.ImageUri</th>\n",
       "      <th>SageMaker.InstanceCount</th>\n",
       "      <th>SageMaker.InstanceType</th>\n",
       "      <th>SageMaker.VolumeSizeInGB</th>\n",
       "      <th>backend</th>\n",
       "      <th>epochs</th>\n",
       "      <th>sagemaker_container_log_level</th>\n",
       "      <th>...</th>\n",
       "      <th>testing - MediaType</th>\n",
       "      <th>testing - Value</th>\n",
       "      <th>training - MediaType</th>\n",
       "      <th>training - Value</th>\n",
       "      <th>SageMaker.DebugHookOutput - MediaType</th>\n",
       "      <th>SageMaker.DebugHookOutput - Value</th>\n",
       "      <th>SageMaker.ModelArtifact - MediaType</th>\n",
       "      <th>SageMaker.ModelArtifact - Value</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Experiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pytorch-training-2021-01-13-16-04-12-404-aws-t...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:389535300735:train...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.m5.xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>\"gloo\"</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>[loan-trial-base-1610553852]</td>\n",
       "      <td>[Classifying-housing-loans-1610551033]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pytorch-training-2021-01-13-15-54-42-229-aws-t...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:389535300735:train...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.m5.xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>\"gloo\"</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>[loan-trial-base-1610553282]</td>\n",
       "      <td>[Classifying-housing-loans-1610551033]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pytorch-training-2021-01-13-15-47-51-045-aws-t...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:389535300735:train...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.m5.xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>\"gloo\"</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>[loan-trial-base-1610552870]</td>\n",
       "      <td>[Classifying-housing-loans-1610551033]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pytorch-training-2021-01-13-15-36-03-172-aws-t...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:389535300735:train...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.m5.xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>\"gloo\"</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>[loan-trial-base-1610552163]</td>\n",
       "      <td>[Classifying-housing-loans-1610551033]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pytorch-training-2021-01-13-15-26-08-344-aws-t...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:389535300735:train...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.m5.xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>\"gloo\"</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>[loan-trial-base-1610551568]</td>\n",
       "      <td>[Classifying-housing-loans-1610551033]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pytorch-training-2021-01-13-15-17-14-722-aws-t...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:389535300735:train...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.m5.xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>\"gloo\"</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-389535300735/distribu...</td>\n",
       "      <td>[loan-trial-base-1610551034]</td>\n",
       "      <td>[Classifying-housing-loans-1610551033]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  TrialComponentName DisplayName  \\\n",
       "0  pytorch-training-2021-01-13-16-04-12-404-aws-t...    Training   \n",
       "1  pytorch-training-2021-01-13-15-54-42-229-aws-t...    Training   \n",
       "2  pytorch-training-2021-01-13-15-47-51-045-aws-t...    Training   \n",
       "3  pytorch-training-2021-01-13-15-36-03-172-aws-t...    Training   \n",
       "4  pytorch-training-2021-01-13-15-26-08-344-aws-t...    Training   \n",
       "5  pytorch-training-2021-01-13-15-17-14-722-aws-t...    Training   \n",
       "\n",
       "                                           SourceArn  \\\n",
       "0  arn:aws:sagemaker:us-east-1:389535300735:train...   \n",
       "1  arn:aws:sagemaker:us-east-1:389535300735:train...   \n",
       "2  arn:aws:sagemaker:us-east-1:389535300735:train...   \n",
       "3  arn:aws:sagemaker:us-east-1:389535300735:train...   \n",
       "4  arn:aws:sagemaker:us-east-1:389535300735:train...   \n",
       "5  arn:aws:sagemaker:us-east-1:389535300735:train...   \n",
       "\n",
       "                                  SageMaker.ImageUri  SageMaker.InstanceCount  \\\n",
       "0  763104351884.dkr.ecr.us-east-1.amazonaws.com/p...                      1.0   \n",
       "1  763104351884.dkr.ecr.us-east-1.amazonaws.com/p...                      1.0   \n",
       "2  763104351884.dkr.ecr.us-east-1.amazonaws.com/p...                      1.0   \n",
       "3  763104351884.dkr.ecr.us-east-1.amazonaws.com/p...                      1.0   \n",
       "4  763104351884.dkr.ecr.us-east-1.amazonaws.com/p...                      1.0   \n",
       "5  763104351884.dkr.ecr.us-east-1.amazonaws.com/p...                      1.0   \n",
       "\n",
       "  SageMaker.InstanceType  SageMaker.VolumeSizeInGB backend  epochs  \\\n",
       "0           ml.m5.xlarge                      30.0  \"gloo\"     3.0   \n",
       "1           ml.m5.xlarge                      30.0  \"gloo\"     3.0   \n",
       "2           ml.m5.xlarge                      30.0  \"gloo\"     3.0   \n",
       "3           ml.m5.xlarge                      30.0  \"gloo\"     3.0   \n",
       "4           ml.m5.xlarge                      30.0  \"gloo\"     3.0   \n",
       "5           ml.m5.xlarge                      30.0  \"gloo\"     3.0   \n",
       "\n",
       "   sagemaker_container_log_level  ... testing - MediaType  \\\n",
       "0                           20.0  ...                None   \n",
       "1                           20.0  ...                None   \n",
       "2                           20.0  ...                None   \n",
       "3                           20.0  ...                None   \n",
       "4                           20.0  ...                None   \n",
       "5                           20.0  ...                None   \n",
       "\n",
       "                                     testing - Value training - MediaType  \\\n",
       "0  s3://sagemaker-us-east-1-389535300735/distribu...                 None   \n",
       "1  s3://sagemaker-us-east-1-389535300735/distribu...                 None   \n",
       "2  s3://sagemaker-us-east-1-389535300735/distribu...                 None   \n",
       "3  s3://sagemaker-us-east-1-389535300735/distribu...                 None   \n",
       "4  s3://sagemaker-us-east-1-389535300735/distribu...                 None   \n",
       "5  s3://sagemaker-us-east-1-389535300735/distribu...                 None   \n",
       "\n",
       "                                    training - Value  \\\n",
       "0  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "1  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "2  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "3  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "4  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "5  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "\n",
       "   SageMaker.DebugHookOutput - MediaType  \\\n",
       "0                                   None   \n",
       "1                                   None   \n",
       "2                                   None   \n",
       "3                                   None   \n",
       "4                                   None   \n",
       "5                                   None   \n",
       "\n",
       "                   SageMaker.DebugHookOutput - Value  \\\n",
       "0  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "1  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "2  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "3  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "4  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "5  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "\n",
       "   SageMaker.ModelArtifact - MediaType  \\\n",
       "0                                 None   \n",
       "1                                 None   \n",
       "2                                 None   \n",
       "3                                 None   \n",
       "4                                 None   \n",
       "5                                 None   \n",
       "\n",
       "                     SageMaker.ModelArtifact - Value  \\\n",
       "0  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "1  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "2  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "3  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "4  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "5  s3://sagemaker-us-east-1-389535300735/distribu...   \n",
       "\n",
       "                         Trials                             Experiments  \n",
       "0  [loan-trial-base-1610553852]  [Classifying-housing-loans-1610551033]  \n",
       "1  [loan-trial-base-1610553282]  [Classifying-housing-loans-1610551033]  \n",
       "2  [loan-trial-base-1610552870]  [Classifying-housing-loans-1610551033]  \n",
       "3  [loan-trial-base-1610552163]  [Classifying-housing-loans-1610551033]  \n",
       "4  [loan-trial-base-1610551568]  [Classifying-housing-loans-1610551033]  \n",
       "5  [loan-trial-base-1610551034]  [Classifying-housing-loans-1610551033]  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=sagemaker_session, \n",
    "    experiment_name=loan_class_experiment.experiment_name,\n",
    "    metric_names=['test:F1']\n",
    ")\n",
    "analytic_table = trial_component_analytics.dataframe()\n",
    "analytic_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrialComponentName                            pytorch-training-2021-01-11-20-03-47-090-aws-t...\n",
       "DisplayName                                                                            Training\n",
       "SourceArn                                     arn:aws:sagemaker:us-east-1:389535300735:train...\n",
       "SageMaker.ImageUri                            763104351884.dkr.ecr.us-east-1.amazonaws.com/p...\n",
       "SageMaker.InstanceCount                                                                       1\n",
       "SageMaker.InstanceType                                                           ml.p3.16xlarge\n",
       "SageMaker.VolumeSizeInGB                                                                     30\n",
       "backend                                                                                  \"nccl\"\n",
       "epochs                                                                                        5\n",
       "sagemaker_container_log_level                                                                20\n",
       "sagemaker_distributed_dataparallel_enabled                                                 true\n",
       "sagemaker_instance_type                                                        \"ml.p3.16xlarge\"\n",
       "sagemaker_job_name                                   \"pytorch-training-2021-01-11-20-03-47-090\"\n",
       "sagemaker_program                                                                    \"train.py\"\n",
       "sagemaker_region                                                                    \"us-east-1\"\n",
       "sagemaker_submit_directory                    \"s3://sagemaker-us-east-1-389535300735/pytorch...\n",
       "test:F1 - Min                                                                            0.0122\n",
       "test:F1 - Max                                                                             0.345\n",
       "test:F1 - Avg                                                                           0.21928\n",
       "test:F1 - StdDev                                                                       0.130183\n",
       "test:F1 - Last                                                                            0.345\n",
       "test:F1 - Count                                                                              10\n",
       "testing - MediaType                                                                        None\n",
       "testing - Value                               s3://sagemaker-us-east-1-389535300735/large_sc...\n",
       "training - MediaType                                                                       None\n",
       "training - Value                              s3://sagemaker-us-east-1-389535300735/large_sc...\n",
       "SageMaker.DebugHookOutput - MediaType                                                      None\n",
       "SageMaker.DebugHookOutput - Value             s3://sagemaker-us-east-1-389535300735/large_sc...\n",
       "SageMaker.ModelArtifact - MediaType                                                        None\n",
       "SageMaker.ModelArtifact - Value               s3://sagemaker-us-east-1-389535300735/large_sc...\n",
       "Trials                                                             [loan-trial-base-1610395426]\n",
       "Experiments                                              [Classifying-housing-loans-1610395241]\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get details for most recent job:\n",
    "analytic_table.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling to Tens of thousands of HPO jobs\n",
    "\n",
    "Having seen how we can launch 1 job, next we will look at some strategies for scaling this to tens of thousands of jobs with Amazon SageMaker for both random and bayesian HPO methods that are come out-of-the-box with SageMaker. \n",
    "\n",
    "Currently, for Bayesian HPO, SageMaker has a limit of 500 *concurrent* jobs across all Bayesian HPO jobs. Below we will provide code for launching the maximum possible Bayesian trials while respecting this limit.\n",
    "\n",
    "Let's look at both strategies in detail. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Strategy\n",
    "\n",
    "For random strategy, each trial in an HPO job is completely independent of one another. In this case, if we want to launch a total of N_tot jobs, we can choose to launch N HPO jobs concurrently with each HPO job having M parallel jobs.\n",
    "\n",
    "To see how you can launch multiple HPO jobs in parallel, refer to the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batched Hyper-parameter Optimization for Bayesian Optimization (Cold Start)\n",
    "\n",
    "For Bayesian HPO, we want to take advantage of the parallelism by training multiple hyper-parameter trials in parallel so the Bayesian algorithm can use the outputs of these parallel jobs to determine the next set of parameters.\n",
    "\n",
    "Again we are limited by the number of concurrent jobs/account = 500, and the default limits are 10 jobs in parallel per job. In that case we can adapt the formula above as follows:\n",
    "\n",
    "![Visual Representation of Batching jobs](img/batching.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2, [2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bayesian_batching_cold_start(total_requested_trials, max_parallel_across_jobs=20, max_parallel_per_job=10, max_candidates_per_job = 500):\n",
    "    '''Given a total number of requested trials, generates the strategy for Bayesian HPO\n",
    "    The strategy is a list (batch_strat) where every element is the number of jobs to execute in parallel. The sum of all elements in the list is\n",
    "    the total number of HPO jobs needed to reach total_requested_trials. For example if batch_strat = [2, 2, 2, 1], means you will run a total of 7\n",
    "    HPO jobs starting with 2 --> 2 ---> 2 ---> 1. \n",
    "    total_requested_trials = number of trails user wants to run.\n",
    "    max_parallel_across_jobs = max number of training jobs across all trials Sagemaker runs in parallel. Limited by instance availability\n",
    "    max_parallel_per_job = max number of parallel jobs to run per HPO job\n",
    "    max_candidates_per_job = total number of training jobs per HPO job'''\n",
    "    batch_strat = [] \n",
    "    tot_jobs_left = total_requested_trials\n",
    "    max_parallel_hpo_jobs = max_parallel_across_jobs//max_parallel_per_job\n",
    "    if total_requested_trials < max_parallel_hpo_jobs*max_candidates_per_job:\n",
    "        batch_strat.append(total_requested_trials//max_candidates_per_job)\n",
    "    else:\n",
    "        while tot_jobs_left > max_parallel_hpo_jobs*max_candidates_per_job:\n",
    "            batch_strat.append(max_parallel_hpo_jobs)\n",
    "            tot_jobs_left -=max_parallel_hpo_jobs*max_candidates_per_job\n",
    "\n",
    "        batch_strat.append(math.ceil((tot_jobs_left)/max_candidates_per_job))\n",
    "    return math.ceil(total_requested_trials/max_candidates_per_job), max_parallel_hpo_jobs, batch_strat\n",
    "                \n",
    "bayesian_batching_cold_start(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's redefine a simpler estimator with just 1 instance. \n",
    "hyperparameter_ranges = {'lr': ContinuousParameter(0.001, 0.1),\n",
    "                         'momentum': CategoricalParameter(list(np.arange(0, 10)/10))}\n",
    "\n",
    "inputs ={'training': train_s3,\n",
    "         'testing':test_s3}\n",
    "\n",
    "objective_metric_name = 'test AUC'\n",
    "objective_type = 'Maximize'\n",
    "metric_definitions = [{'Name': 'test AUC',\n",
    "                       'Regex': 'Test set AUC: ([0-9\\\\.]+)'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create  the estimator for HPO\n",
    "estimator = PyTorch(entry_point=\"train_cpu.py\",\n",
    "                    role=role,\n",
    "                    framework_version='1.6.0',\n",
    "                    py_version='py36',\n",
    "                    source_dir='./code',\n",
    "                    output_path = f's3://{bucket}/{prefix}/output',\n",
    "                    instance_count=1, \n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    instance_type='ml.m5.xlarge', \n",
    "                    hyperparameters={\n",
    "                        'epochs': 10, # run more epochs for HPO.\n",
    "                        'backend': 'gloo' #gloo for cpu, nccl for gpu\n",
    "                    }\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the HPO job on a GPU\n",
    "\n",
    "As before, to run this HPO job using a GPU and test out the SM distributed library on large scale datasets, make the following code changes.\n",
    "\n",
    "\n",
    "1. replace entry_point = \"train.py\"\n",
    "\n",
    "2. add the following code in \"\" after metric_definitions: \"distribution={'smdistributed':{\n",
    "                                            'dataparallel':{\n",
    "                                                    'enabled': True\n",
    "                                                 }\n",
    "                                          }\n",
    "                                     },\"\n",
    " \n",
    " \n",
    "3. In hyperparameters, replace 'backend': 'nccl'\n",
    "\n",
    "This will instantiate the sm distributed library on the containers. To learn more about Sm distributed, see this link: \n",
    "https://aws.amazon.com/sagemaker/distributed-training/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polling jobs\n",
    "You can potentially reduce your overall wall time by polling continuously for completed HPO jobs. This way, if the number of launched HPO jobs is less than a certain threshold, you can start a new one. Use the code below to implement the polling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to launch a desired number of \"n_parallel\" HPO jobs simultaneously\n",
    "def _parallel_hpo_no_polling(job_name_prefix, n_parallel, inputs, max_candidates_per_job, max_parallel_per_job):\n",
    "    \"\"\"kicks off N_parallel Bayesian HPO jobs in parallel\n",
    "    job_name_prefix: user specified prefix for job names\n",
    "    n_parallel: Number of HPO jobs to start in parallel\n",
    "    inputs: training and test data s3 paths\n",
    "    max_candidates_per_job: number of training jobs to run in each HPO job in total\n",
    "    max_parallel_per_job: number of training jobs to run in parallel in each job\n",
    "    \n",
    "    \"\"\"\n",
    "    # kick off n_parallel jobs simultaneously and returns all the job names \n",
    "    tuning_job_names = []\n",
    "    for i in range(n_parallel):\n",
    "        timestamp_suffix = strftime(\"%d-%H-%M-%S\", gmtime())\n",
    "        try:\n",
    "            tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=max_candidates_per_job,\n",
    "                            max_parallel_jobs=max_parallel_per_job,\n",
    "                            base_tuning_job_name=f'{job_name_prefix}-{timestamp_suffix}',\n",
    "                            objective_type=objective_type)\n",
    "        # fit the tuner to the inputs and include it as part of experiments\n",
    "            tuner.fit(inputs, \n",
    "                  wait=False) # set wait=False, so you can launch other jobs in parallel.\n",
    "            tuning_job_names.append(tuner.latest_tuning_job.name)\n",
    "            sleep(1) #this is required otherwise you will get an error for using the same tuning job name\n",
    "            print(tuning_job_names)\n",
    "        except Exception as e:\n",
    "            sleep(5)\n",
    "    return tuning_job_names\n",
    "\n",
    "#orchestration and polling logic\n",
    "def poll_and_run(job_name_prefix, inputs, max_total_candidates, max_parallel_across_jobs, max_candidates_per_job, max_parallel_per_job):\n",
    "    \"\"\"Polls for number of running HPO jobs. If less than max_parallel , starts a new one. \n",
    "    job_name_prefix: the name prefix to give all your training jobs\n",
    "    max_total_candidates: how many total trails to run across all HPO jobs\n",
    "    max_candidates_per_job: how many total trails to run for 1 HPO job \n",
    "    max_parallel_per_job: how many trials to run in parallel for a given HPO job (fixed to 10 without limit increases). \n",
    "    max_parallel_across_jobs: how many concurrent trials to run in parallel across all HPO jobs\n",
    "    \"\"\"\n",
    "    #get how many jobs to run in total and concurrently\n",
    "    max_num, max_parallel, _ = bayesian_batching_cold_start(max_total_candidates, \n",
    "                                                            max_parallel_across_jobs=max_parallel_across_jobs,\n",
    "                                                            max_parallel_per_job=max_parallel_per_job,\n",
    "                                                            max_candidates_per_job = max_candidates_per_job\n",
    "                                                           )\n",
    "    \n",
    "    # continuously polls for running jobs -- if they are less than the required number, then launches a new one. \n",
    "    try:\n",
    "        all_jobs = sm.list_hyper_parameter_tuning_jobs(SortBy='CreationTime', SortOrder='Descending', \n",
    "                                                       NameContains=job_name_prefix)['HyperParameterTuningJobSummaries']\n",
    "        all_jobs = [i['HyperParameterTuningJobName'] for i in all_jobs]\n",
    "\n",
    "        if len(all_jobs)==0:\n",
    "            raise ValueError\n",
    "        \n",
    "        else:\n",
    "            print(\"Continuing where you left off...\")\n",
    "            response_list = [sm.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=i)['HyperParameterTuningJobStatus']\n",
    "                         for i in all_jobs]\n",
    "            num_left = max_num - response_list.count(\"Completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Starting a set of HPO jobs with the prefix {job_name_prefix} ...\")\n",
    "        num_left = max_num\n",
    "        #kick off the first set of jobs\n",
    "        all_jobs += _parallel_hpo_no_polling(job_name_prefix, min(max_parallel, num_left), inputs, max_candidates_per_job, max_parallel_per_job)\n",
    "    \n",
    "    \n",
    "    while num_left >0:\n",
    "        response_list = [sm.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=i)['HyperParameterTuningJobStatus']\n",
    "                         for i in all_jobs]\n",
    "        running_jobs = response_list.count(\"InProgress\") # look for the jobs that are running. \n",
    "        print(f\"number of completed jobs = {response_list.count('Completed')}\")\n",
    "        sleep(10)\n",
    "        if running_jobs < max_parallel and len(all_jobs) < max_num:\n",
    "            all_jobs += _parallel_hpo_no_polling(job_name_prefix, min(max_parallel-running_jobs, num_left), inputs, max_candidates_per_job, max_parallel_per_job)\n",
    "        num_left = max_num - response_list.count(\"Completed\")\n",
    "                \n",
    "    return all_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing where you left off...\n",
      "number of completed jobs = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-36-4-210114-1436\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-14-36-4-210114-1436']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-36-4-210114-1436\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-36-5-210114-1436\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-36-5-210114-1436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-14-36-4-210114-1436', 'newtrials-14-14-36-5-210114-1436']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-36-5-210114-1436\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-37-0-210114-1437\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-37-0-210114-1437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-14-36-4-210114-1436', 'newtrials-14-14-36-5-210114-1436', 'newtrials-14-14-37-0-210114-1437']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-37-1-210114-1437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-14-36-4-210114-1436', 'newtrials-14-14-36-5-210114-1436', 'newtrials-14-14-37-0-210114-1437', 'newtrials-14-14-37-1-210114-1437']\n",
      "number of completed jobs = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-37-2-210114-1437\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-37-2-210114-1437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-14-37-2-210114-1437']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-37-2-210114-1437\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-37-3-210114-1437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-14-37-2-210114-1437', 'newtrials-14-14-37-3-210114-1437']\n",
      "number of completed jobs = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-37-4-210114-1437\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-37-4-210114-1437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-14-37-4-210114-1437']\n",
      "number of completed jobs = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-38-0-210114-1438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-14-38-0-210114-1438']\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 0\n",
      "number of completed jobs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-44-5-210114-1444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-14-44-5-210114-1444']\n",
      "number of completed jobs = 1\n",
      "number of completed jobs = 1\n",
      "number of completed jobs = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-45-2-210114-1445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-14-45-2-210114-1445']\n",
      "number of completed jobs = 2\n",
      "number of completed jobs = 2\n",
      "number of completed jobs = 2\n",
      "number of completed jobs = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-46-1-210114-1446\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-46-1-210114-1446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-14-46-1-210114-1446']\n",
      "number of completed jobs = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-46-3-210114-1446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-14-46-3-210114-1446']\n",
      "number of completed jobs = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-46-4-210114-1446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-14-46-4-210114-1446']\n",
      "number of completed jobs = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-46-5-210114-1446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-14-46-5-210114-1446']\n",
      "number of completed jobs = 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-47-1-210114-1447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-14-47-1-210114-1447']\n",
      "number of completed jobs = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-14-47-2-210114-1447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-14-47-2-210114-1447']\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 8\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 16\n",
      "number of completed jobs = 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-03-3-210114-1503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-15-03-3-210114-1503']\n",
      "number of completed jobs = 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-03-5-210114-1503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-15-03-5-210114-1503']\n",
      "number of completed jobs = 18\n",
      "number of completed jobs = 18\n",
      "number of completed jobs = 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-04-2-210114-1504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-15-04-2-210114-1504']\n",
      "number of completed jobs = 19\n",
      "number of completed jobs = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-04-5-210114-1504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-15-04-5-210114-1504']\n",
      "number of completed jobs = 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-05-0-210114-1505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-15-05-0-210114-1505']\n",
      "number of completed jobs = 21\n",
      "number of completed jobs = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-05-2-210114-1505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-15-05-2-210114-1505']\n",
      "number of completed jobs = 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-05-4-210114-1505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-15-05-4-210114-1505']\n",
      "number of completed jobs = 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-05-5-210114-1505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-15-05-5-210114-1505']\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 24\n",
      "number of completed jobs = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-12-5-210114-1512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-15-12-5-210114-1512']\n",
      "number of completed jobs = 25\n",
      "number of completed jobs = 25\n",
      "number of completed jobs = 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-13-3-210114-1513\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-13-3-210114-1513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-15-13-3-210114-1513']\n",
      "number of completed jobs = 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-13-5-210114-1513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-15-13-5-210114-1513']\n",
      "number of completed jobs = 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-14-0-210114-1514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-15-14-0-210114-1514']\n",
      "number of completed jobs = 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-14-2-210114-1514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-15-14-2-210114-1514']\n",
      "number of completed jobs = 29\n",
      "number of completed jobs = 29\n",
      "number of completed jobs = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-15-0-210114-1515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-15-15-0-210114-1515']\n",
      "number of completed jobs = 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-15-1-210114-1515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-15-15-1-210114-1515']\n",
      "number of completed jobs = 31\n",
      "number of completed jobs = 31\n",
      "number of completed jobs = 31\n",
      "number of completed jobs = 31\n",
      "number of completed jobs = 31\n",
      "number of completed jobs = 31\n",
      "number of completed jobs = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: newtrials-14-15-16-4-210114-1516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newtrials-14-15-16-4-210114-1516']\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n",
      "number of completed jobs = 32\n"
     ]
    }
   ],
   "source": [
    "# Test out this loop\n",
    "alljobs = poll_and_run('newtrials', inputs, max_total_candidates=260, max_parallel_across_jobs = 20, max_candidates_per_job=4, max_parallel_per_job=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the results from all the HPO jobs based on the custom metric specified\n",
    "def get_best_job(all_jobs_list):\n",
    "    \"\"\"Get the best job from the list of all the jobs completed.\n",
    "    Objective is to maximize a particular value such as AUC or F1 score\"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for job in all_jobs_list:\n",
    "        tuner = sagemaker.HyperparameterTuningJobAnalytics(job)\n",
    "        full_df = tuner.dataframe()\n",
    "        tuning_job_result = sm.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=job)\n",
    "        is_maximize = (tuning_job_result['HyperParameterTuningJobConfig']['HyperParameterTuningJobObjective']['Type'] == 'Maximize')\n",
    "        if len(full_df) > 0:\n",
    "            df = pd.concat([df, full_df[full_df['FinalObjectiveValue'] < float('inf')]])\n",
    "    if len(df) > 0:\n",
    "        df = df.sort_values('FinalObjectiveValue', ascending=is_maximize)\n",
    "        print(\"Number of training jobs with valid objective: %d\" % len(df))\n",
    "        print({\"lowest\":min(df['FinalObjectiveValue']),\"highest\": max(df['FinalObjectiveValue'])})\n",
    "        pd.set_option('display.max_colwidth', -1)  # Don't truncate TrainingJobName\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No training jobs have reported valid results yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 4 threads.\n",
      "WARNING:py.warnings:/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:17: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training jobs with valid objective: 8\n",
      "{'lowest': 0.6139000058174133, 'highest': 0.6557999849319458}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>momentum</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001230</td>\n",
       "      <td>\"0.7\"</td>\n",
       "      <td>hpotrails-13-18-23-4-210113-1823-002-9f95a3e9</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.6139</td>\n",
       "      <td>2021-01-13 18:26:17+00:00</td>\n",
       "      <td>2021-01-13 18:27:52+00:00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006406</td>\n",
       "      <td>\"0.0\"</td>\n",
       "      <td>hpotrails-13-18-23-4-210113-1823-003-4aec77ff</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.6230</td>\n",
       "      <td>2021-01-13 18:30:10+00:00</td>\n",
       "      <td>2021-01-13 18:31:43+00:00</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010226</td>\n",
       "      <td>\"0.0\"</td>\n",
       "      <td>hpotrails-13-18-23-4-210113-1823-001-57d9d7fc</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.6318</td>\n",
       "      <td>2021-01-13 18:26:12+00:00</td>\n",
       "      <td>2021-01-13 18:27:46+00:00</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002248</td>\n",
       "      <td>\"0.9\"</td>\n",
       "      <td>hpotrails-13-18-22-4-210113-1822-003-5a57c9d6</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.6409</td>\n",
       "      <td>2021-01-13 18:29:47+00:00</td>\n",
       "      <td>2021-01-13 18:31:20+00:00</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002353</td>\n",
       "      <td>\"0.9\"</td>\n",
       "      <td>hpotrails-13-18-22-4-210113-1822-004-3a1a6c9b</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.6416</td>\n",
       "      <td>2021-01-13 18:29:20+00:00</td>\n",
       "      <td>2021-01-13 18:30:55+00:00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014784</td>\n",
       "      <td>\"0.7\"</td>\n",
       "      <td>hpotrails-13-18-22-4-210113-1822-001-cc54b06a</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>2021-01-13 18:25:11+00:00</td>\n",
       "      <td>2021-01-13 18:27:19+00:00</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021520</td>\n",
       "      <td>\"0.8\"</td>\n",
       "      <td>hpotrails-13-18-22-4-210113-1822-002-fef78ff9</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.6516</td>\n",
       "      <td>2021-01-13 18:25:16+00:00</td>\n",
       "      <td>2021-01-13 18:26:52+00:00</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046496</td>\n",
       "      <td>\"0.9\"</td>\n",
       "      <td>hpotrails-13-18-23-4-210113-1823-004-b8c4ad97</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>2021-01-13 18:30:16+00:00</td>\n",
       "      <td>2021-01-13 18:32:05+00:00</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lr momentum                                TrainingJobName  \\\n",
       "2  0.001230  \"0.7\"    hpotrails-13-18-23-4-210113-1823-002-9f95a3e9   \n",
       "1  0.006406  \"0.0\"    hpotrails-13-18-23-4-210113-1823-003-4aec77ff   \n",
       "3  0.010226  \"0.0\"    hpotrails-13-18-23-4-210113-1823-001-57d9d7fc   \n",
       "1  0.002248  \"0.9\"    hpotrails-13-18-22-4-210113-1822-003-5a57c9d6   \n",
       "0  0.002353  \"0.9\"    hpotrails-13-18-22-4-210113-1822-004-3a1a6c9b   \n",
       "3  0.014784  \"0.7\"    hpotrails-13-18-22-4-210113-1822-001-cc54b06a   \n",
       "2  0.021520  \"0.8\"    hpotrails-13-18-22-4-210113-1822-002-fef78ff9   \n",
       "0  0.046496  \"0.9\"    hpotrails-13-18-23-4-210113-1823-004-b8c4ad97   \n",
       "\n",
       "  TrainingJobStatus  FinalObjectiveValue         TrainingStartTime  \\\n",
       "2  Completed         0.6139              2021-01-13 18:26:17+00:00   \n",
       "1  Completed         0.6230              2021-01-13 18:30:10+00:00   \n",
       "3  Completed         0.6318              2021-01-13 18:26:12+00:00   \n",
       "1  Completed         0.6409              2021-01-13 18:29:47+00:00   \n",
       "0  Completed         0.6416              2021-01-13 18:29:20+00:00   \n",
       "3  Completed         0.6474              2021-01-13 18:25:11+00:00   \n",
       "2  Completed         0.6516              2021-01-13 18:25:16+00:00   \n",
       "0  Completed         0.6558              2021-01-13 18:30:16+00:00   \n",
       "\n",
       "            TrainingEndTime  TrainingElapsedTimeSeconds  \n",
       "2 2021-01-13 18:27:52+00:00  95.0                        \n",
       "1 2021-01-13 18:31:43+00:00  93.0                        \n",
       "3 2021-01-13 18:27:46+00:00  94.0                        \n",
       "1 2021-01-13 18:31:20+00:00  93.0                        \n",
       "0 2021-01-13 18:30:55+00:00  95.0                        \n",
       "3 2021-01-13 18:27:19+00:00  128.0                       \n",
       "2 2021-01-13 18:26:52+00:00  96.0                        \n",
       "0 2021-01-13 18:32:05+00:00  109.0                       "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_job(alljobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example shows how the batching strategy works for cold-start cases. For warm start, we need a different strategy as we want to use the outputs of the previous job as the inputs into the next job. Look at the code below to run a warm start batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serial Hyper-parameter Optimization (warm start)\n",
    "\n",
    "For warm start -- we want to use the outputs of our previous run, as the input of the next one. For this reason, we need to run the jobs serially, as shown in the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def large_scale_hpo_warmstart(inputs, max_total_jobs, max_jobs_per_hpo_job, max_parallel_per_job):\n",
    "    base_hpo_job_name = 'FTW'\n",
    "    timestamp_suffix = strftime(\"%d-%H-%M-%S\", gmtime())\n",
    "    tuning_job_name = lambda i : f\"{base_hpo_job_name}-{timestamp_suffix}-{i}\"\n",
    "    current_jobs_completed = 0\n",
    "    job_names_list = []\n",
    "    while current_jobs_completed < max_total_jobs:\n",
    "        jobs_to_launch = min(max_total_jobs - current_jobs_completed, max_jobs_per_hpo_job)\n",
    "\n",
    "        hpo_job_config = dict(\n",
    "            estimator=estimator,\n",
    "            objective_metric_name=objective_metric_name,\n",
    "            metric_definitions=metric_definitions,\n",
    "            hyperparameter_ranges=hyperparameter_ranges,\n",
    "            max_jobs=jobs_to_launch,\n",
    "            strategy=\"Bayesian\",\n",
    "            objective_type=objective_type,\n",
    "            max_parallel_jobs=max_parallel_per_job,\n",
    "        )\n",
    "\n",
    "        if current_jobs_completed > 0:\n",
    "            parent_tuning_job_name = tuning_job_name(current_jobs_completed)\n",
    "            warm_start_config = WarmStartConfig(\n",
    "                WarmStartTypes.IDENTICAL_DATA_AND_ALGORITHM,\n",
    "                parents={parent_tuning_job_name}\n",
    "            )\n",
    "            hpo_job_config.update(dict(\n",
    "                base_tuning_job_name=parent_tuning_job_name,\n",
    "                warm_start_config=warm_start_config\n",
    "            ))\n",
    "\n",
    "        tuner = HyperparameterTuner(**hpo_job_config)\n",
    "        tuner.fit(\n",
    "            inputs,\n",
    "            job_name=tuning_job_name(current_jobs_completed + jobs_to_launch),\n",
    "            logs=True,\n",
    "        )\n",
    "        tuner.wait()\n",
    "        job_names_list.append(tuner.latest_tuning_job.name)\n",
    "        current_jobs_completed += jobs_to_launch\n",
    "    return job_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................................................................!\n",
      "!\n",
      "......................................................................................................................................................!\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "job_list = large_scale_hpo_warmstart(inputs, 2, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "Number of training jobs with valid objective: 2\n",
      "{'lowest': 0.2502000033855438, 'highest': 0.3003999888896942}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>momentum</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005666</td>\n",
       "      <td>\"0.0\"</td>\n",
       "      <td>FTW-10-22-37-49-2-001-7628c487</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.2502</td>\n",
       "      <td>2020-12-10 22:57:37+00:00</td>\n",
       "      <td>2020-12-10 23:07:59+00:00</td>\n",
       "      <td>622.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002055</td>\n",
       "      <td>\"0.1\"</td>\n",
       "      <td>FTW-10-22-37-49-1-001-6a2bdc3b</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.3004</td>\n",
       "      <td>2020-12-10 22:40:42+00:00</td>\n",
       "      <td>2020-12-10 22:52:16+00:00</td>\n",
       "      <td>694.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lr momentum                 TrainingJobName TrainingJobStatus  \\\n",
       "0  0.005666  \"0.0\"    FTW-10-22-37-49-2-001-7628c487  Completed          \n",
       "0  0.002055  \"0.1\"    FTW-10-22-37-49-1-001-6a2bdc3b  Completed          \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "0  0.2502              2020-12-10 22:57:37+00:00 2020-12-10 23:07:59+00:00   \n",
       "0  0.3004              2020-12-10 22:40:42+00:00 2020-12-10 22:52:16+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "0  622.0                       \n",
       "0  694.0                       "
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_job(job_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we have covered a number of advanced topics suitable for ML researchers who run large scale deep learning training and HPO jobs.\n",
    "\n",
    "\n",
    "1. We have covered how to run large numbers of HPO jobs using a continuous polling technique. \n",
    "\n",
    "2. We have provided code in the code folder to allow you to use the SM Distributed library as well as GPUs for faster training\n",
    "\n",
    "3. Finally we covered how you can optimize for a custom metric, by publishing your custom metric to stdout and passing in the regex in the metric_definition during HPO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Topic (using RayTune with PyTorch)\n",
    "\n",
    "Ray is an open source library for HPO developed from this paper: https://arxiv.org/pdf/1807.05118.pdf our of UC Berkeley. Ray integrates with many of the popular open and closed source HPO search algorithms and schedulers. To see how Ray works with Amazon SageMaker, try out the estimator below which runs the train_ray.py script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Ray job on a GPU\n",
    "\n",
    "To test Ray with a single node GPU cluster, make the following code changes.\n",
    "\n",
    "1. replace entry_point = \"train_ray.py\"\n",
    "\n",
    "2. In hyperparameters, replace 'backend': 'nccl'\n",
    "\n",
    "This will instantiate the sm distributed library on the containers. To learn more about Sm distributed, see this link: \n",
    "https://aws.amazon.com/sagemaker/distributed-training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2021-01-13-17-15-49-016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-13 17:15:49 Starting - Starting the training job...\n",
      "2021-01-13 17:15:52 Starting - Launching requested ML instances.........\n",
      "2021-01-13 17:17:24 Starting - Preparing the instances for training...\n",
      "2021-01-13 17:18:01 Downloading - Downloading input data...\n",
      "2021-01-13 17:18:49 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-01-13 17:18:49,658 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-01-13 17:18:49,661 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-01-13 17:18:49,673 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-01-13 17:18:51,098 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-01-13 17:18:51,476 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting sagemaker==2.19.0\n",
      "  Downloading sagemaker-2.19.0.tar.gz (395 kB)\u001b[0m\n",
      "\u001b[34mCollecting ray[tune]\n",
      "  Downloading ray-1.1.0-cp36-cp36m-manylinux2014_x86_64.whl (48.5 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tabulate in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (0.8.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.19.0->-r requirements.txt (line 1)) (20.3.0)\u001b[0m\n",
      "\u001b[34mCollecting boto3>=1.16.32\n",
      "  Downloading boto3-1.16.53-py2.py3-none-any.whl (130 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.19.0->-r requirements.txt (line 1)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.19.0->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.1 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.19.0->-r requirements.txt (line 1)) (3.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.19.0->-r requirements.txt (line 1)) (0.1.5)\u001b[0m\n",
      "\u001b[34mCollecting smdebug_rulesconfig>=1.0.0\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=1.4.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.19.0->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.19.0->-r requirements.txt (line 1)) (20.4)\u001b[0m\n",
      "\u001b[34mCollecting jsonschema\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: colorama in /opt/conda/lib/python3.6/site-packages (from ray[tune]->-r requirements.txt (line 2)) (0.4.3)\u001b[0m\n",
      "\u001b[34mCollecting msgpack<2.0.0,>=1.0.0\n",
      "  Downloading msgpack-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (272 kB)\u001b[0m\n",
      "\u001b[34mCollecting opencensus\n",
      "  Downloading opencensus-0.7.11-py2.py3-none-any.whl (127 kB)\u001b[0m\n",
      "\u001b[34mCollecting prometheus-client>=0.7.1\n",
      "  Downloading prometheus_client-0.9.0-py2.py3-none-any.whl (53 kB)\u001b[0m\n",
      "\u001b[34mCollecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.28.1\n",
      "  Downloading grpcio-1.34.0-cp36-cp36m-manylinux2014_x86_64.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from ray[tune]->-r requirements.txt (line 2)) (2.24.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.6/site-packages (from ray[tune]->-r requirements.txt (line 2)) (3.7.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.6/site-packages (from ray[tune]->-r requirements.txt (line 2)) (7.1.2)\u001b[0m\n",
      "\u001b[34mCollecting aioredis\n",
      "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[34mCollecting py-spy>=0.2.0\n",
      "  Downloading py_spy-0.3.3-py2.py3-none-manylinux1_x86_64.whl (2.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting redis>=3.5.0\n",
      "  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\u001b[0m\n",
      "\u001b[34mCollecting colorful\n",
      "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from ray[tune]->-r requirements.txt (line 2)) (5.3.1)\u001b[0m\n",
      "\u001b[34mCollecting gpustat\n",
      "  Downloading gpustat-0.6.0.tar.gz (78 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp-cors\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses; python_version < \"3.7\" and extra == \"tune\" in /opt/conda/lib/python3.6/site-packages (from ray[tune]->-r requirements.txt (line 2)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas; extra == \"tune\" in /opt/conda/lib/python3.6/site-packages (from ray[tune]->-r requirements.txt (line 2)) (1.1.3)\u001b[0m\n",
      "\u001b[34mCollecting tensorboardX; extra == \"tune\"\n",
      "  Downloading tensorboardX-2.1-py2.py3-none-any.whl (308 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker==2.19.0->-r requirements.txt (line 1)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker==2.19.0->-r requirements.txt (line 1)) (0.3.3)\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.20.0,>=1.19.53\n",
      "  Downloading botocore-1.19.53-py2.py3-none-any.whl (7.2 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from google-pasta->sagemaker==2.19.0->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker==2.19.0->-r requirements.txt (line 1)) (3.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->sagemaker==2.19.0->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mCollecting pyrsistent>=0.14.0\n",
      "  Downloading pyrsistent-0.17.3.tar.gz (106 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from jsonschema->ray[tune]->-r requirements.txt (line 2)) (50.3.0.post20201006)\u001b[0m\n",
      "\u001b[34mCollecting opencensus-context==0.1.2\n",
      "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-api-core<2.0.0,>=1.0.0\n",
      "  Downloading google_api_core-1.24.1-py2.py3-none-any.whl (92 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->ray[tune]->-r requirements.txt (line 2)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->ray[tune]->-r requirements.txt (line 2)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->ray[tune]->-r requirements.txt (line 2)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->ray[tune]->-r requirements.txt (line 2)) (2020.11.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp->ray[tune]->-r requirements.txt (line 2)) (1.6.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /opt/conda/lib/python3.6/site-packages (from aiohttp->ray[tune]->-r requirements.txt (line 2)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp->ray[tune]->-r requirements.txt (line 2)) (3.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.6/site-packages (from aiohttp->ray[tune]->-r requirements.txt (line 2)) (5.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.6.5 in /opt/conda/lib/python3.6/site-packages (from aiohttp->ray[tune]->-r requirements.txt (line 2)) (3.7.4.3)\u001b[0m\n",
      "\u001b[34mCollecting hiredis\n",
      "  Downloading hiredis-1.1.0-cp36-cp36m-manylinux2010_x86_64.whl (61 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /opt/conda/lib/python3.6/site-packages (from gpustat->ray[tune]->-r requirements.txt (line 2)) (7.352.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.6/site-packages (from gpustat->ray[tune]->-r requirements.txt (line 2)) (5.6.7)\u001b[0m\n",
      "\u001b[34mCollecting blessings>=1.6\n",
      "  Downloading blessings-1.7-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas; extra == \"tune\"->ray[tune]->-r requirements.txt (line 2)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas; extra == \"tune\"->ray[tune]->-r requirements.txt (line 2)) (2020.1)\u001b[0m\n",
      "\u001b[34mCollecting contextvars; python_version >= \"3.6\" and python_version < \"3.7\"\n",
      "  Downloading contextvars-2.4.tar.gz (9.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<2.0dev,>=1.21.1\n",
      "  Downloading google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\u001b[0m\n",
      "\u001b[34mCollecting immutables>=0.9\n",
      "  Downloading immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98 kB)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.0-py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /opt/conda/lib/python3.6/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]->-r requirements.txt (line 2)) (4.5)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]->-r requirements.txt (line 2)) (0.4.8)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sagemaker, gpustat, pyrsistent, contextvars\n",
      "  Building wheel for sagemaker (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.19.0-py2.py3-none-any.whl size=553631 sha256=d34dc4ff0cc1b74bf3617c60785329e3274c57e9d7c2cd878fdada6f77a81893\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/5f/a2/ae75ce6341001c1605ccc4675808a04f5eb1d0b441ffec4b88\n",
      "  Building wheel for gpustat (setup.py): started\n",
      "  Building wheel for gpustat (setup.py): finished with status 'done'\n",
      "  Created wheel for gpustat: filename=gpustat-0.6.0-py3-none-any.whl size=12617 sha256=8e5e94ab8c05177f554104ad1d59895f91950ae04650b5522d96cf51f04d7939\n",
      "  Stored in directory: /root/.cache/pip/wheels/50/da/35/fe2cfb3bc47822299f5e124a599d56f00b30ec0b328db16b9f\n",
      "  Building wheel for pyrsistent (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for pyrsistent (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrsistent: filename=pyrsistent-0.17.3-cp36-cp36m-linux_x86_64.whl size=112550 sha256=cedc87b763969bba833529c0efa4e36599c14549124f30a3c0d6be56f2280e5e\n",
      "  Stored in directory: /root/.cache/pip/wheels/34/13/19/294da8e11bce7e563afee51251b9fa878185e14f4b5caf00cb\n",
      "  Building wheel for contextvars (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for contextvars (setup.py): finished with status 'done'\n",
      "  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7665 sha256=69a460d34fd16f541b14dd78b02fa53d8e0de3a4d0a39f0fc7980ca6c86c2189\n",
      "  Stored in directory: /root/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\u001b[0m\n",
      "\u001b[34mSuccessfully built sagemaker gpustat pyrsistent contextvars\u001b[0m\n",
      "\u001b[34mInstalling collected packages: botocore, boto3, smdebug-rulesconfig, sagemaker, pyrsistent, jsonschema, msgpack, immutables, contextvars, opencensus-context, googleapis-common-protos, cachetools, pyasn1-modules, google-auth, google-api-core, opencensus, prometheus-client, filelock, grpcio, hiredis, aioredis, py-spy, redis, colorful, blessings, gpustat, aiohttp-cors, tensorboardX, ray\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.19.19\n",
      "    Uninstalling botocore-1.19.19:\n",
      "      Successfully uninstalled botocore-1.19.19\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.16.19\n",
      "    Uninstalling boto3-1.16.19:\n",
      "      Successfully uninstalled boto3-1.16.19\n",
      "  Attempting uninstall: smdebug-rulesconfig\n",
      "    Found existing installation: smdebug-rulesconfig 0.1.6\n",
      "    Uninstalling smdebug-rulesconfig-0.1.6:\n",
      "      Successfully uninstalled smdebug-rulesconfig-0.1.6\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.16.4.dev0\n",
      "    Uninstalling sagemaker-2.16.4.dev0:\n",
      "      Successfully uninstalled sagemaker-2.16.4.dev0\u001b[0m\n",
      "\u001b[34mSuccessfully installed aiohttp-cors-0.7.0 aioredis-1.3.1 blessings-1.7 boto3-1.16.53 botocore-1.19.53 cachetools-4.2.0 colorful-0.5.4 contextvars-2.4 filelock-3.0.12 google-api-core-1.24.1 google-auth-1.24.0 googleapis-common-protos-1.52.0 gpustat-0.6.0 grpcio-1.34.0 hiredis-1.1.0 immutables-0.14 jsonschema-3.2.0 msgpack-1.0.2 opencensus-0.7.11 opencensus-context-0.1.2 prometheus-client-0.9.0 py-spy-0.3.3 pyasn1-modules-0.2.8 pyrsistent-0.17.3 ray-1.1.0 redis-3.5.3 sagemaker-2.19.0 smdebug-rulesconfig-1.0.1 tensorboardX-2.1\u001b[0m\n",
      "\u001b[34m2021-01-13 17:19:07,444 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-01-13 17:19:07,457 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-01-13 17:19:07,469 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-01-13 17:19:07,480 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"testing\": \"/opt/ml/input/data/testing\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 7\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"testing\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2021-01-13-17-15-49-016\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-389535300735/pytorch-training-2021-01-13-17-15-49-016/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_ray_cpu\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_ray_cpu.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"epochs\":7}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_ray_cpu.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"testing\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_ray_cpu\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-389535300735/pytorch-training-2021-01-13-17-15-49-016/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":7},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2021-01-13-17-15-49-016\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-389535300735/pytorch-training-2021-01-13-17-15-49-016/source/sourcedir.tar.gz\",\"module_name\":\"train_ray_cpu\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_ray_cpu.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"7\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TESTING=/opt/ml/input/data/testing\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=7\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train_ray_cpu.py --backend gloo --epochs 7\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mStarting training ....\u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 2.0/15.4 GiB\u001b[0m\n",
      "\u001b[34mUsing AsyncHyperBand: num_stopped=0\u001b[0m\n",
      "\u001b[34mBracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\u001b[0m\n",
      "\u001b[34mResources requested: 4/4 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /root/ray_results/DEFAULT_2021-01-13_17-19-12\u001b[0m\n",
      "\u001b[34mNumber of trials: 1/10 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------+----------+-------+------+------+-------------+\u001b[0m\n",
      "\u001b[34m| Trial name          | status   | loc   |   l1 |   l2 |          lr |\u001b[0m\n",
      "\u001b[34m|---------------------+----------+-------+------+------+-------------|\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00000 | RUNNING  |       |  256 |   16 | 0.000594009 |\u001b[0m\n",
      "\u001b[34m+---------------------+----------+-------+------+------+-------------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m Picked data parallel\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.056 algo-1:167 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.168 algo-1:167 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.168 algo-1:167 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.169 algo-1:167 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.170 algo-1:167 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.170 algo-1:167 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.218 algo-1:167 INFO hook.py:550] name:module.fc1.weight count_params:5888\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.218 algo-1:167 INFO hook.py:550] name:module.fc1.bias count_params:256\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.219 algo-1:167 INFO hook.py:550] name:module.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.219 algo-1:167 INFO hook.py:550] name:module.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.219 algo-1:167 INFO hook.py:550] name:module.bn2.weight count_params:16\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.219 algo-1:167 INFO hook.py:550] name:module.bn2.bias count_params:16\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.219 algo-1:167 INFO hook.py:550] name:module.fc2.weight count_params:4096\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.219 algo-1:167 INFO hook.py:550] name:module.fc2.bias count_params:16\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.219 algo-1:167 INFO hook.py:550] name:module.fc3.weight count_params:32\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.219 algo-1:167 INFO hook.py:550] name:module.fc3.bias count_params:2\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.219 algo-1:167 INFO hook.py:552] Total Trainable Params: 10834\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.219 algo-1:167 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m [2021-01-13 17:19:14.221 algo-1:167 INFO hook.py:476] Hook is writing from the hook with pid: 167\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=167)#033[0m \u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00000:\n",
      "  accuracy: 0.7736666666666666\n",
      "  date: 2021-01-13_17-19-15\n",
      "  done: false\n",
      "  experiment_id: 9a6cb516e7eb42dc959428450709e487\n",
      "  f1score: 0.034139402560455195\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.5944432616233826\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 167\n",
      "  roc: 0.565432565149237\n",
      "  time_since_restore: 1.3090829849243164\n",
      "  time_this_iter_s: 1.3090829849243164\n",
      "  time_total_s: 1.3090829849243164\n",
      "  timestamp: 1610558355\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '74908_00000'\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 2.2/15.4 GiB\u001b[0m\n",
      "\u001b[34mUsing AsyncHyperBand: num_stopped=0\u001b[0m\n",
      "\u001b[34mBracket: Iter 4.000: -0.6338475942611694 | Iter 2.000: -0.6139503717422485 | Iter 1.000: -0.5944432616233826\u001b[0m\n",
      "\u001b[34mResources requested: 4/4 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /root/ray_results/DEFAULT_2021-01-13_17-19-12\u001b[0m\n",
      "\u001b[34mNumber of trials: 2/10 (1 PENDING, 1 RUNNING)\u001b[0m\n",
      "\u001b[34m+---------------------+----------+------------------+------+------+-------------+----------+----------------------+----------+\u001b[0m\n",
      "\u001b[34m| Trial name          | status   | loc              |   l1 |   l2 |          lr |     loss |   training_iteration |      roc |\u001b[0m\n",
      "\u001b[34m|---------------------+----------+------------------+------+------+-------------+----------+----------------------+----------|\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00000 | RUNNING  | 10.2.122.211:167 |  256 |   16 | 0.000594009 | 0.641291 |                    5 | 0.576968 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00001 | PENDING  |                  |   64 |    8 | 0.000273087 |          |                      |          |\u001b[0m\n",
      "\u001b[34m+---------------------+----------+------------------+------+------+-------------+----------+----------------------+----------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00000:\n",
      "  accuracy: 0.701\n",
      "  date: 2021-01-13_17-19-20\n",
      "  done: true\n",
      "  experiment_id: 9a6cb516e7eb42dc959428450709e487\n",
      "  f1score: 0.2777777777777778\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 7\n",
      "  loss: 0.6554732918739319\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 167\n",
      "  roc: 0.5788156149961714\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 6.221158504486084\n",
      "  time_this_iter_s: 0.769111156463623\n",
      "  time_total_s: 6.221158504486084\n",
      "  timestamp: 1610558360\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: '74908_00000'\n",
      "  \u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m Picked data parallel\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.273 algo-1:166 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.330 algo-1:166 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.331 algo-1:166 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.331 algo-1:166 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.332 algo-1:166 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.332 algo-1:166 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.363 algo-1:166 INFO hook.py:550] name:module.fc1.weight count_params:1472\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.363 algo-1:166 INFO hook.py:550] name:module.fc1.bias count_params:64\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.363 algo-1:166 INFO hook.py:550] name:module.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.363 algo-1:166 INFO hook.py:550] name:module.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.363 algo-1:166 INFO hook.py:550] name:module.bn2.weight count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.363 algo-1:166 INFO hook.py:550] name:module.bn2.bias count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.363 algo-1:166 INFO hook.py:550] name:module.fc2.weight count_params:512\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.363 algo-1:166 INFO hook.py:550] name:module.fc2.bias count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.363 algo-1:166 INFO hook.py:550] name:module.fc3.weight count_params:16\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.363 algo-1:166 INFO hook.py:550] name:module.fc3.bias count_params:2\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.363 algo-1:166 INFO hook.py:552] Total Trainable Params: 2218\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.363 algo-1:166 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m [2021-01-13 17:19:21.365 algo-1:166 INFO hook.py:476] Hook is writing from the hook with pid: 166\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=166)#033[0m \u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00001:\n",
      "  accuracy: 0.27116666666666667\n",
      "  date: 2021-01-13_17-19-21\n",
      "  done: true\n",
      "  experiment_id: 122f6715616c4543a9543a144bd32eba\n",
      "  f1score: 0.35089802582751967\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.8553117513656616\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 166\n",
      "  roc: 0.5637705731473861\n",
      "  time_since_restore: 0.6128544807434082\n",
      "  time_this_iter_s: 0.6128544807434082\n",
      "  time_total_s: 0.6128544807434082\n",
      "  timestamp: 1610558361\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '74908_00001'\n",
      "  \u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m Picked data parallel\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.862 algo-1:169 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.920 algo-1:169 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.920 algo-1:169 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.920 algo-1:169 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.921 algo-1:169 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.921 algo-1:169 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.973 algo-1:169 INFO hook.py:550] name:module.fc1.weight count_params:92\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.973 algo-1:169 INFO hook.py:550] name:module.fc1.bias count_params:4\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.973 algo-1:169 INFO hook.py:550] name:module.bn1.weight count_params:4\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.973 algo-1:169 INFO hook.py:550] name:module.bn1.bias count_params:4\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.973 algo-1:169 INFO hook.py:550] name:module.bn2.weight count_params:16\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.974 algo-1:169 INFO hook.py:550] name:module.bn2.bias count_params:16\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.974 algo-1:169 INFO hook.py:550] name:module.fc2.weight count_params:64\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.974 algo-1:169 INFO hook.py:550] name:module.fc2.bias count_params:16\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.974 algo-1:169 INFO hook.py:550] name:module.fc3.weight count_params:32\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.974 algo-1:169 INFO hook.py:550] name:module.fc3.bias count_params:2\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.974 algo-1:169 INFO hook.py:552] Total Trainable Params: 250\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.974 algo-1:169 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m [2021-01-13 17:19:22.976 algo-1:169 INFO hook.py:476] Hook is writing from the hook with pid: 169\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=169)#033[0m \u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00002:\n",
      "  accuracy: 0.4013333333333333\n",
      "  date: 2021-01-13_17-19-23\n",
      "  done: true\n",
      "  experiment_id: 264eac560fc5467084861a76e5009349\n",
      "  f1score: 0.3320937151357382\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.728167712688446\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 169\n",
      "  roc: 0.5129135845776203\n",
      "  time_since_restore: 0.5088748931884766\n",
      "  time_this_iter_s: 0.5088748931884766\n",
      "  time_total_s: 0.5088748931884766\n",
      "  timestamp: 1610558363\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '74908_00002'\n",
      "  \u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m Picked data parallel\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.400 algo-1:168 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.458 algo-1:168 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.458 algo-1:168 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.458 algo-1:168 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.459 algo-1:168 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.459 algo-1:168 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.486 algo-1:168 INFO hook.py:550] name:module.fc1.weight count_params:368\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.486 algo-1:168 INFO hook.py:550] name:module.fc1.bias count_params:16\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.486 algo-1:168 INFO hook.py:550] name:module.bn1.weight count_params:16\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.486 algo-1:168 INFO hook.py:550] name:module.bn1.bias count_params:16\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.486 algo-1:168 INFO hook.py:550] name:module.bn2.weight count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.486 algo-1:168 INFO hook.py:550] name:module.bn2.bias count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.486 algo-1:168 INFO hook.py:550] name:module.fc2.weight count_params:128\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.486 algo-1:168 INFO hook.py:550] name:module.fc2.bias count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.487 algo-1:168 INFO hook.py:550] name:module.fc3.weight count_params:16\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.487 algo-1:168 INFO hook.py:550] name:module.fc3.bias count_params:2\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.487 algo-1:168 INFO hook.py:552] Total Trainable Params: 586\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.487 algo-1:168 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m [2021-01-13 17:19:24.489 algo-1:168 INFO hook.py:476] Hook is writing from the hook with pid: 168\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=168)#033[0m \u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00003:\n",
      "  accuracy: 0.7355\n",
      "  date: 2021-01-13_17-19-24\n",
      "  done: false\n",
      "  experiment_id: 3d7217836bd441acba81d71219cd8de4\n",
      "  f1score: 0.12658227848101264\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6801182627677917\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 168\n",
      "  roc: 0.4434269782043857\n",
      "  time_since_restore: 0.4995555877685547\n",
      "  time_this_iter_s: 0.4995555877685547\n",
      "  time_total_s: 0.4995555877685547\n",
      "  timestamp: 1610558364\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '74908_00003'\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 2.1/15.4 GiB\u001b[0m\n",
      "\u001b[34mUsing AsyncHyperBand: num_stopped=3\u001b[0m\n",
      "\u001b[34mBracket: Iter 4.000: -0.6338475942611694 | Iter 2.000: -0.6139503717422485 | Iter 1.000: -0.7041429877281189\u001b[0m\n",
      "\u001b[34mResources requested: 4/4 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /root/ray_results/DEFAULT_2021-01-13_17-19-12\u001b[0m\n",
      "\u001b[34mNumber of trials: 5/10 (1 PENDING, 1 RUNNING, 3 TERMINATED)\u001b[0m\n",
      "\u001b[34m+---------------------+------------+------------------+------+------+-------------+----------+----------------------+----------+\u001b[0m\n",
      "\u001b[34m| Trial name          | status     | loc              |   l1 |   l2 |          lr |     loss |   training_iteration |      roc |\u001b[0m\n",
      "\u001b[34m|---------------------+------------+------------------+------+------+-------------+----------+----------------------+----------|\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00003 | RUNNING    | 10.2.122.211:168 |   16 |    8 | 0.0678701   | 0.680118 |                    1 | 0.443427 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00004 | PENDING    |                  |    8 |    8 | 0.0004862   |          |                      |          |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00000 | TERMINATED |                  |  256 |   16 | 0.000594009 | 0.655473 |                    7 | 0.578816 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00001 | TERMINATED |                  |   64 |    8 | 0.000273087 | 0.855312 |                    1 | 0.563771 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00002 | TERMINATED |                  |    4 |   16 | 0.000188217 | 0.728168 |                    1 | 0.512914 |\u001b[0m\n",
      "\u001b[34m+---------------------+------------+------------------+------+------+-------------+----------+----------------------+----------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00003:\n",
      "  accuracy: 0.7546666666666667\n",
      "  date: 2021-01-13_17-19-25\n",
      "  done: true\n",
      "  experiment_id: 3d7217836bd441acba81d71219cd8de4\n",
      "  f1score: 0.12066905615292713\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.6724809408187866\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 168\n",
      "  roc: 0.4907669331883546\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.760002613067627\n",
      "  time_this_iter_s: 0.26044702529907227\n",
      "  time_total_s: 0.760002613067627\n",
      "  timestamp: 1610558365\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: '74908_00003'\n",
      "  \u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m Picked data parallel\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.493 algo-1:292 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.551 algo-1:292 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.551 algo-1:292 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.551 algo-1:292 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.552 algo-1:292 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.552 algo-1:292 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.580 algo-1:292 INFO hook.py:550] name:module.fc1.weight count_params:184\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.580 algo-1:292 INFO hook.py:550] name:module.fc1.bias count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.581 algo-1:292 INFO hook.py:550] name:module.bn1.weight count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.581 algo-1:292 INFO hook.py:550] name:module.bn1.bias count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.581 algo-1:292 INFO hook.py:550] name:module.bn2.weight count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.581 algo-1:292 INFO hook.py:550] name:module.bn2.bias count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.581 algo-1:292 INFO hook.py:550] name:module.fc2.weight count_params:64\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.581 algo-1:292 INFO hook.py:550] name:module.fc2.bias count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.581 algo-1:292 INFO hook.py:550] name:module.fc3.weight count_params:16\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.581 algo-1:292 INFO hook.py:550] name:module.fc3.bias count_params:2\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.581 algo-1:292 INFO hook.py:552] Total Trainable Params: 314\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.581 algo-1:292 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m [2021-01-13 17:19:26.583 algo-1:292 INFO hook.py:476] Hook is writing from the hook with pid: 292\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=292)#033[0m \u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00004:\n",
      "  accuracy: 0.5356666666666666\n",
      "  date: 2021-01-13_17-19-26\n",
      "  done: false\n",
      "  experiment_id: 2d87776c8b174ccd96d852e87e6bf580\n",
      "  f1score: 0.3922338568935428\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.682863175868988\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 292\n",
      "  roc: 0.6229633394013198\n",
      "  time_since_restore: 0.49344611167907715\n",
      "  time_this_iter_s: 0.49344611167907715\n",
      "  time_total_s: 0.49344611167907715\n",
      "  timestamp: 1610558366\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '74908_00004'\n",
      "  \u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00004:\n",
      "  accuracy: 0.4145\n",
      "  date: 2021-01-13_17-19-27\n",
      "  done: true\n",
      "  experiment_id: 2d87776c8b174ccd96d852e87e6bf580\n",
      "  f1score: 0.37591046367027897\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.7164316177368164\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 292\n",
      "  roc: 0.6169811342753954\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.7492609024047852\n",
      "  time_this_iter_s: 0.255814790725708\n",
      "  time_total_s: 0.7492609024047852\n",
      "  timestamp: 1610558367\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: '74908_00004'\n",
      "  \u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m Picked data parallel\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.543 algo-1:318 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.600 algo-1:318 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.601 algo-1:318 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.601 algo-1:318 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.602 algo-1:318 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.602 algo-1:318 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.624 algo-1:318 INFO hook.py:550] name:module.fc1.weight count_params:5888\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.624 algo-1:318 INFO hook.py:550] name:module.fc1.bias count_params:256\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.624 algo-1:318 INFO hook.py:550] name:module.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.624 algo-1:318 INFO hook.py:550] name:module.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.624 algo-1:318 INFO hook.py:550] name:module.bn2.weight count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.624 algo-1:318 INFO hook.py:550] name:module.bn2.bias count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.624 algo-1:318 INFO hook.py:550] name:module.fc2.weight count_params:2048\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.624 algo-1:318 INFO hook.py:550] name:module.fc2.bias count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.624 algo-1:318 INFO hook.py:550] name:module.fc3.weight count_params:16\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.624 algo-1:318 INFO hook.py:550] name:module.fc3.bias count_params:2\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.624 algo-1:318 INFO hook.py:552] Total Trainable Params: 8746\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.624 algo-1:318 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m [2021-01-13 17:19:28.627 algo-1:318 INFO hook.py:476] Hook is writing from the hook with pid: 318\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=318)#033[0m \u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00005:\n",
      "  accuracy: 0.788\n",
      "  date: 2021-01-13_17-19-29\n",
      "  done: false\n",
      "  experiment_id: 305b2814b3064a1392ff0960c3c0440a\n",
      "  f1score: 0.004694835680751174\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.640284538269043\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 318\n",
      "  roc: 0.5861045276040081\n",
      "  time_since_restore: 1.0661108493804932\n",
      "  time_this_iter_s: 1.0661108493804932\n",
      "  time_total_s: 1.0661108493804932\n",
      "  timestamp: 1610558369\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '74908_00005'\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 2.1/15.4 GiB\u001b[0m\n",
      "\u001b[34mUsing AsyncHyperBand: num_stopped=5\u001b[0m\n",
      "\u001b[34mBracket: Iter 4.000: -0.6338475942611694 | Iter 2.000: -0.6628638803958893 | Iter 1.000: -0.6814907193183899\u001b[0m\n",
      "\u001b[34mResources requested: 4/4 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /root/ray_results/DEFAULT_2021-01-13_17-19-12\u001b[0m\n",
      "\u001b[34mNumber of trials: 7/10 (1 PENDING, 1 RUNNING, 5 TERMINATED)\u001b[0m\n",
      "\u001b[34m+---------------------+------------+------------------+------+------+-------------+----------+----------------------+----------+\u001b[0m\n",
      "\u001b[34m| Trial name          | status     | loc              |   l1 |   l2 |          lr |     loss |   training_iteration |      roc |\u001b[0m\n",
      "\u001b[34m|---------------------+------------+------------------+------+------+-------------+----------+----------------------+----------|\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00005 | RUNNING    | 10.2.122.211:318 |  256 |    8 | 0.00224274  | 0.653247 |                    2 | 0.588285 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00006 | PENDING    |                  |    8 |  128 | 0.000274089 |          |                      |          |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00000 | TERMINATED |                  |  256 |   16 | 0.000594009 | 0.655473 |                    7 | 0.578816 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00001 | TERMINATED |                  |   64 |    8 | 0.000273087 | 0.855312 |                    1 | 0.563771 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00002 | TERMINATED |                  |    4 |   16 | 0.000188217 | 0.728168 |                    1 | 0.512914 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00003 | TERMINATED |                  |   16 |    8 | 0.0678701   | 0.672481 |                    2 | 0.490767 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00004 | TERMINATED |                  |    8 |    8 | 0.0004862   | 0.716432 |                    2 | 0.616981 |\u001b[0m\n",
      "\u001b[34m+---------------------+------------+------------------+------+------+-------------+----------+----------------------+----------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00005:\n",
      "  accuracy: 0.5386666666666666\n",
      "  date: 2021-01-13_17-19-31\n",
      "  done: true\n",
      "  experiment_id: 305b2814b3064a1392ff0960c3c0440a\n",
      "  f1score: 0.3651376146788991\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 4\n",
      "  loss: 0.6712490320205688\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 318\n",
      "  roc: 0.5950979897358919\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.42917799949646\n",
      "  time_this_iter_s: 0.7803308963775635\n",
      "  time_total_s: 3.42917799949646\n",
      "  timestamp: 1610558371\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: '74908_00005'\n",
      "  \u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m Picked data parallel\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.286 algo-1:346 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.345 algo-1:346 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.345 algo-1:346 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.346 algo-1:346 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.347 algo-1:346 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.347 algo-1:346 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.374 algo-1:346 INFO hook.py:550] name:module.fc1.weight count_params:184\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.374 algo-1:346 INFO hook.py:550] name:module.fc1.bias count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.374 algo-1:346 INFO hook.py:550] name:module.bn1.weight count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.374 algo-1:346 INFO hook.py:550] name:module.bn1.bias count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.374 algo-1:346 INFO hook.py:550] name:module.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.374 algo-1:346 INFO hook.py:550] name:module.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.374 algo-1:346 INFO hook.py:550] name:module.fc2.weight count_params:1024\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.374 algo-1:346 INFO hook.py:550] name:module.fc2.bias count_params:128\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.374 algo-1:346 INFO hook.py:550] name:module.fc3.weight count_params:256\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.374 algo-1:346 INFO hook.py:550] name:module.fc3.bias count_params:2\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.374 algo-1:346 INFO hook.py:552] Total Trainable Params: 1874\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.374 algo-1:346 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m [2021-01-13 17:19:33.376 algo-1:346 INFO hook.py:476] Hook is writing from the hook with pid: 346\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=346)#033[0m \u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00006:\n",
      "  accuracy: 0.6588333333333334\n",
      "  date: 2021-01-13_17-19-33\n",
      "  done: false\n",
      "  experiment_id: 62768e8749fb445bb187c36be4463485\n",
      "  f1score: 0.32819166393173616\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6584025025367737\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 346\n",
      "  roc: 0.6088210000634615\n",
      "  time_since_restore: 0.7488605976104736\n",
      "  time_this_iter_s: 0.7488605976104736\n",
      "  time_total_s: 0.7488605976104736\n",
      "  timestamp: 1610558373\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '74908_00006'\n",
      "  \u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00006:\n",
      "  accuracy: 0.6603333333333333\n",
      "  date: 2021-01-13_17-19-34\n",
      "  done: true\n",
      "  experiment_id: 62768e8749fb445bb187c36be4463485\n",
      "  f1score: 0.31702412868632707\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.6695888042449951\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 346\n",
      "  roc: 0.5981243209326876\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 1.2554128170013428\n",
      "  time_this_iter_s: 0.5065522193908691\n",
      "  time_total_s: 1.2554128170013428\n",
      "  timestamp: 1610558374\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: '74908_00006'\n",
      "  \u001b[0m\n",
      "\n",
      "2021-01-13 17:19:50 Uploading - Uploading generated training model\u001b[34m#033[2m#033[36m(pid=372)#033[0m Picked data parallel\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.869 algo-1:372 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.927 algo-1:372 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.927 algo-1:372 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.927 algo-1:372 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.928 algo-1:372 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.928 algo-1:372 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.956 algo-1:372 INFO hook.py:550] name:module.fc1.weight count_params:92\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.957 algo-1:372 INFO hook.py:550] name:module.fc1.bias count_params:4\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.957 algo-1:372 INFO hook.py:550] name:module.bn1.weight count_params:4\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.957 algo-1:372 INFO hook.py:550] name:module.bn1.bias count_params:4\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.957 algo-1:372 INFO hook.py:550] name:module.bn2.weight count_params:32\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.957 algo-1:372 INFO hook.py:550] name:module.bn2.bias count_params:32\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.957 algo-1:372 INFO hook.py:550] name:module.fc2.weight count_params:128\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.957 algo-1:372 INFO hook.py:550] name:module.fc2.bias count_params:32\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.957 algo-1:372 INFO hook.py:550] name:module.fc3.weight count_params:64\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.957 algo-1:372 INFO hook.py:550] name:module.fc3.bias count_params:2\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.957 algo-1:372 INFO hook.py:552] Total Trainable Params: 394\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.957 algo-1:372 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m [2021-01-13 17:19:35.959 algo-1:372 INFO hook.py:476] Hook is writing from the hook with pid: 372\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=372)#033[0m \u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00007:\n",
      "  accuracy: 0.753\n",
      "  date: 2021-01-13_17-19-36\n",
      "  done: false\n",
      "  experiment_id: be316f1757e74bef9ce8da027e2126a1\n",
      "  f1score: 0.16176470588235295\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6355916857719421\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 372\n",
      "  roc: 0.6217730613049851\n",
      "  time_since_restore: 0.5237972736358643\n",
      "  time_this_iter_s: 0.5237972736358643\n",
      "  time_total_s: 0.5237972736358643\n",
      "  timestamp: 1610558376\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '74908_00007'\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 2.1/15.4 GiB\u001b[0m\n",
      "\u001b[34mUsing AsyncHyperBand: num_stopped=7\u001b[0m\n",
      "\u001b[34mBracket: Iter 4.000: -0.6525483131408691 | Iter 2.000: -0.6695888042449951 | Iter 1.000: -0.6692603826522827\u001b[0m\n",
      "\u001b[34mResources requested: 4/4 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /root/ray_results/DEFAULT_2021-01-13_17-19-12\u001b[0m\n",
      "\u001b[34mNumber of trials: 9/10 (1 PENDING, 1 RUNNING, 7 TERMINATED)\u001b[0m\n",
      "\u001b[34m+---------------------+------------+------------------+------+------+-------------+----------+----------------------+----------+\u001b[0m\n",
      "\u001b[34m| Trial name          | status     | loc              |   l1 |   l2 |          lr |     loss |   training_iteration |      roc |\u001b[0m\n",
      "\u001b[34m|---------------------+------------+------------------+------+------+-------------+----------+----------------------+----------|\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00007 | RUNNING    | 10.2.122.211:372 |    4 |   32 | 0.00720385  | 0.635592 |                    1 | 0.621773 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00008 | PENDING    |                  |    8 |   64 | 0.0462769   |          |                      |          |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00000 | TERMINATED |                  |  256 |   16 | 0.000594009 | 0.655473 |                    7 | 0.578816 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00001 | TERMINATED |                  |   64 |    8 | 0.000273087 | 0.855312 |                    1 | 0.563771 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00002 | TERMINATED |                  |    4 |   16 | 0.000188217 | 0.728168 |                    1 | 0.512914 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00003 | TERMINATED |                  |   16 |    8 | 0.0678701   | 0.672481 |                    2 | 0.490767 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00004 | TERMINATED |                  |    8 |    8 | 0.0004862   | 0.716432 |                    2 | 0.616981 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00005 | TERMINATED |                  |  256 |    8 | 0.00224274  | 0.671249 |                    4 | 0.595098 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00006 | TERMINATED |                  |    8 |  128 | 0.000274089 | 0.669589 |                    2 | 0.598124 |\u001b[0m\n",
      "\u001b[34m+---------------------+------------+------------------+------+------+-------------+----------+----------------------+----------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00007:\n",
      "  accuracy: 0.6326666666666667\n",
      "  date: 2021-01-13_17-19-37\n",
      "  done: true\n",
      "  experiment_id: be316f1757e74bef9ce8da027e2126a1\n",
      "  f1score: 0.3727945361411497\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 4\n",
      "  loss: 0.6766563057899475\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 372\n",
      "  roc: 0.6154337394370314\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 1.388545036315918\n",
      "  time_this_iter_s: 0.2851376533508301\n",
      "  time_total_s: 1.388545036315918\n",
      "  timestamp: 1610558377\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: '74908_00007'\n",
      "  \u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m Picked data parallel\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.570 algo-1:400 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.629 algo-1:400 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.629 algo-1:400 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.630 algo-1:400 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.631 algo-1:400 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.631 algo-1:400 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.654 algo-1:400 INFO hook.py:550] name:module.fc1.weight count_params:184\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.654 algo-1:400 INFO hook.py:550] name:module.fc1.bias count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.654 algo-1:400 INFO hook.py:550] name:module.bn1.weight count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.654 algo-1:400 INFO hook.py:550] name:module.bn1.bias count_params:8\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.654 algo-1:400 INFO hook.py:550] name:module.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.654 algo-1:400 INFO hook.py:550] name:module.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.654 algo-1:400 INFO hook.py:550] name:module.fc2.weight count_params:512\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.654 algo-1:400 INFO hook.py:550] name:module.fc2.bias count_params:64\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.654 algo-1:400 INFO hook.py:550] name:module.fc3.weight count_params:128\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.654 algo-1:400 INFO hook.py:550] name:module.fc3.bias count_params:2\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.654 algo-1:400 INFO hook.py:552] Total Trainable Params: 1042\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.654 algo-1:400 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m [2021-01-13 17:19:38.657 algo-1:400 INFO hook.py:476] Hook is writing from the hook with pid: 400\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=400)#033[0m \u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00008:\n",
      "  accuracy: 0.5648333333333333\n",
      "  date: 2021-01-13_17-19-39\n",
      "  done: false\n",
      "  experiment_id: c73de40035f240c3bee05a2f0350dedb\n",
      "  f1score: 0.3598921304241236\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6465420126914978\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 400\n",
      "  roc: 0.5788592551950575\n",
      "  time_since_restore: 0.6148655414581299\n",
      "  time_this_iter_s: 0.6148655414581299\n",
      "  time_total_s: 0.6148655414581299\n",
      "  timestamp: 1610558379\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '74908_00008'\n",
      "  \u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00008:\n",
      "  accuracy: 0.4891666666666667\n",
      "  date: 2021-01-13_17-19-39\n",
      "  done: true\n",
      "  experiment_id: c73de40035f240c3bee05a2f0350dedb\n",
      "  f1score: 0.3712820512820513\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.6697756052017212\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 400\n",
      "  roc: 0.6066982042058159\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.9778954982757568\n",
      "  time_this_iter_s: 0.36302995681762695\n",
      "  time_total_s: 0.9778954982757568\n",
      "  timestamp: 1610558379\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: '74908_00008'\n",
      "  \u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m Picked data parallel\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:40.960 algo-1:426 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.019 algo-1:426 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.020 algo-1:426 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.020 algo-1:426 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.021 algo-1:426 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.021 algo-1:426 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.050 algo-1:426 INFO hook.py:550] name:module.fc1.weight count_params:2944\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.050 algo-1:426 INFO hook.py:550] name:module.fc1.bias count_params:128\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.050 algo-1:426 INFO hook.py:550] name:module.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.050 algo-1:426 INFO hook.py:550] name:module.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.050 algo-1:426 INFO hook.py:550] name:module.bn2.weight count_params:16\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.050 algo-1:426 INFO hook.py:550] name:module.bn2.bias count_params:16\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.050 algo-1:426 INFO hook.py:550] name:module.fc2.weight count_params:2048\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.050 algo-1:426 INFO hook.py:550] name:module.fc2.bias count_params:16\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.050 algo-1:426 INFO hook.py:550] name:module.fc3.weight count_params:32\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.050 algo-1:426 INFO hook.py:550] name:module.fc3.bias count_params:2\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.050 algo-1:426 INFO hook.py:552] Total Trainable Params: 5458\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.051 algo-1:426 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m [2021-01-13 17:19:41.053 algo-1:426 INFO hook.py:476] Hook is writing from the hook with pid: 426\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(pid=426)#033[0m \u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00009:\n",
      "  accuracy: 0.7043333333333334\n",
      "  date: 2021-01-13_17-19-41\n",
      "  done: false\n",
      "  experiment_id: 5941fe62a4f341018bc8211d3bf78870\n",
      "  f1score: 0.16241737488196412\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6427074670791626\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 426\n",
      "  roc: 0.5389911018966996\n",
      "  time_since_restore: 0.7606017589569092\n",
      "  time_this_iter_s: 0.7606017589569092\n",
      "  time_total_s: 0.7606017589569092\n",
      "  timestamp: 1610558381\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '74908_00009'\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 2.1/15.4 GiB\u001b[0m\n",
      "\u001b[34mUsing AsyncHyperBand: num_stopped=9\u001b[0m\n",
      "\u001b[34mBracket: Iter 4.000: -0.6712490320205688 | Iter 2.000: -0.6695888042449951 | Iter 1.000: -0.6524722576141357\u001b[0m\n",
      "\u001b[34mResources requested: 4/4 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /root/ray_results/DEFAULT_2021-01-13_17-19-12\u001b[0m\n",
      "\u001b[34mNumber of trials: 10/10 (1 RUNNING, 9 TERMINATED)\u001b[0m\n",
      "\u001b[34m+---------------------+------------+------------------+------+------+-------------+----------+----------------------+----------+\u001b[0m\n",
      "\u001b[34m| Trial name          | status     | loc              |   l1 |   l2 |          lr |     loss |   training_iteration |      roc |\u001b[0m\n",
      "\u001b[34m|---------------------+------------+------------------+------+------+-------------+----------+----------------------+----------|\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00009 | RUNNING    | 10.2.122.211:426 |  128 |   16 | 0.023928    | 0.642707 |                    1 | 0.538991 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00000 | TERMINATED |                  |  256 |   16 | 0.000594009 | 0.655473 |                    7 | 0.578816 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00001 | TERMINATED |                  |   64 |    8 | 0.000273087 | 0.855312 |                    1 | 0.563771 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00002 | TERMINATED |                  |    4 |   16 | 0.000188217 | 0.728168 |                    1 | 0.512914 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00003 | TERMINATED |                  |   16 |    8 | 0.0678701   | 0.672481 |                    2 | 0.490767 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00004 | TERMINATED |                  |    8 |    8 | 0.0004862   | 0.716432 |                    2 | 0.616981 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00005 | TERMINATED |                  |  256 |    8 | 0.00224274  | 0.671249 |                    4 | 0.595098 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00006 | TERMINATED |                  |    8 |  128 | 0.000274089 | 0.669589 |                    2 | 0.598124 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00007 | TERMINATED |                  |    4 |   32 | 0.00720385  | 0.676656 |                    4 | 0.615434 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00008 | TERMINATED |                  |    8 |   64 | 0.0462769   | 0.669776 |                    2 | 0.606698 |\u001b[0m\n",
      "\u001b[34m+---------------------+------------+------------------+------+------+-------------+----------+----------------------+----------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mResult for DEFAULT_74908_00009:\n",
      "  accuracy: 0.5668333333333333\n",
      "  date: 2021-01-13_17-19-44\n",
      "  done: true\n",
      "  experiment_id: 5941fe62a4f341018bc8211d3bf78870\n",
      "  f1score: 0.38572441503190735\n",
      "  hostname: ip-10-2-122-211.ec2.internal\n",
      "  iterations_since_restore: 7\n",
      "  loss: 0.6507893204689026\n",
      "  node_ip: 10.2.122.211\n",
      "  pid: 426\n",
      "  roc: 0.6260095751926457\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.73087477684021\n",
      "  time_this_iter_s: 0.5109460353851318\n",
      "  time_total_s: 3.73087477684021\n",
      "  timestamp: 1610558384\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: '74908_00009'\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 2.1/15.4 GiB\u001b[0m\n",
      "\u001b[34mUsing AsyncHyperBand: num_stopped=10\u001b[0m\n",
      "\u001b[34mBracket: Iter 4.000: -0.6525483131408691 | Iter 2.000: -0.6630603671073914 | Iter 1.000: -0.6524722576141357\u001b[0m\n",
      "\u001b[34mResources requested: 0/4 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /root/ray_results/DEFAULT_2021-01-13_17-19-12\u001b[0m\n",
      "\u001b[34mNumber of trials: 10/10 (10 TERMINATED)\u001b[0m\n",
      "\u001b[34m+---------------------+------------+-------+------+------+-------------+----------+----------------------+----------+\u001b[0m\n",
      "\u001b[34m| Trial name          | status     | loc   |   l1 |   l2 |          lr |     loss |   training_iteration |      roc |\u001b[0m\n",
      "\u001b[34m|---------------------+------------+-------+------+------+-------------+----------+----------------------+----------|\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00000 | TERMINATED |       |  256 |   16 | 0.000594009 | 0.655473 |                    7 | 0.578816 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00001 | TERMINATED |       |   64 |    8 | 0.000273087 | 0.855312 |                    1 | 0.563771 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00002 | TERMINATED |       |    4 |   16 | 0.000188217 | 0.728168 |                    1 | 0.512914 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00003 | TERMINATED |       |   16 |    8 | 0.0678701   | 0.672481 |                    2 | 0.490767 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00004 | TERMINATED |       |    8 |    8 | 0.0004862   | 0.716432 |                    2 | 0.616981 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00005 | TERMINATED |       |  256 |    8 | 0.00224274  | 0.671249 |                    4 | 0.595098 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00006 | TERMINATED |       |    8 |  128 | 0.000274089 | 0.669589 |                    2 | 0.598124 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00007 | TERMINATED |       |    4 |   32 | 0.00720385  | 0.676656 |                    4 | 0.615434 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00008 | TERMINATED |       |    8 |   64 | 0.0462769   | 0.669776 |                    2 | 0.606698 |\u001b[0m\n",
      "\u001b[34m| DEFAULT_74908_00009 | TERMINATED |       |  128 |   16 | 0.023928    | 0.650789 |                    7 | 0.62601  |\u001b[0m\n",
      "\u001b[34m+---------------------+------------+-------+------+------+-------------+----------+----------------------+----------+\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mBest trial config: {'l1': 128, 'l2': 16, 'lr': 0.0239279798108536}\u001b[0m\n",
      "\u001b[34mBest trial final validation loss: 0.6507893204689026\u001b[0m\n",
      "\u001b[34mBest trial final validation accuracy: 0.5668333333333333\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.611 algo-1:69 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.670 algo-1:69 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.671 algo-1:69 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.671 algo-1:69 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.672 algo-1:69 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.672 algo-1:69 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.754 algo-1:69 INFO hook.py:550] name:module.fc1.weight count_params:2944\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.754 algo-1:69 INFO hook.py:550] name:module.fc1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.754 algo-1:69 INFO hook.py:550] name:module.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.754 algo-1:69 INFO hook.py:550] name:module.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.754 algo-1:69 INFO hook.py:550] name:module.bn2.weight count_params:16\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.754 algo-1:69 INFO hook.py:550] name:module.bn2.bias count_params:16\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.754 algo-1:69 INFO hook.py:550] name:module.fc2.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.754 algo-1:69 INFO hook.py:550] name:module.fc2.bias count_params:16\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.754 algo-1:69 INFO hook.py:550] name:module.fc3.weight count_params:32\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.755 algo-1:69 INFO hook.py:550] name:module.fc3.bias count_params:2\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.755 algo-1:69 INFO hook.py:552] Total Trainable Params: 5458\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.755 algo-1:69 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-01-13 17:19:44.757 algo-1:69 INFO hook.py:476] Hook is writing from the hook with pid: 69\n",
      "\u001b[0m\n",
      "\u001b[34mTest set Average loss: 0.6471, Test Accuracy: 58%;\n",
      "\u001b[0m\n",
      "\u001b[34mTest set F1-score: 0.3815, Test set AUC: 0.6202 \n",
      "\u001b[0m\n",
      "\u001b[34mBest trial test set accuracy: None\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m2021-01-13 17:19:47,899 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-01-13 17:19:58 Completed - Training job completed\n",
      "Training seconds: 117\n",
      "Billable seconds: 117\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"train_ray_cpu.py\", #put requirements.txt file to install ray\n",
    "                    role=role,\n",
    "                    source_dir='./code',\n",
    "                    framework_version='1.6.0',\n",
    "                    py_version='py3',\n",
    "                    output_path = f's3://{bucket}/{prefix}/output',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m5.xlarge',\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'epochs': 7,\n",
    "                        'backend': 'gloo' # gloo for CPU and nccl for GPU\n",
    "                    },\n",
    "                   disable_profiler=True)\n",
    "\n",
    "inputs ={'training': train_s3,\n",
    "         'testing':test_s3}\n",
    "\n",
    "estimator.fit(inputs, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this notebook, you have seen how to run large scale HPO jobs using SageMaker HPO tuning feature on a credit card default dataset. \n",
    "\n",
    "Wherever possible, with minimal code changes you can use this notebook to also use GPUs, as we have provided all the required code in the code folder associated with this repo. \n",
    "\n",
    "Happy Hyperparameter tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
