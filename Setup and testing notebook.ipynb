{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "First, let us do some setup. \n",
    "\n",
    "* Create a SageMaker execution role. This role should have access to S3 and permission to create SageMaker HPO jobs. Save the ARN of this role. We need to paste this ARN in the line of code that defines `role` in our Lambda function later. \n",
    "\n",
    "* Create a SQS queue, note the URL of your queue and set `queue_url` in Lambda Function to this URL later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lambda layer for SageMaker Python SDK\n",
    "\n",
    "`sagemakersdk.zip` is provided in this repo. Run the following code to create `sagemakersdk` layer. Make sure your enter the right bucket name in the script below. \n",
    "\n",
    "Please note `sagemakersdk` layer must work together with `AWSLambda-Python37-SciPy1x` layer. `AWSLambda-Python37-SciPy1x` is provided by AWS and you don't need to create it yourself. We will add both layers to our Lambda function in later step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "aws s3 cp sagemakersdk.zip <s3 bucket>\n",
    "aws lambda publish-layer-version --layer-name sagemakersdk --content S3Bucket=<s3 bucket>,S3Key=sagemakersdk.zip --compatible-runtimes python3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lambda function\n",
    "\n",
    "The code for Lambda function looks like below. It checks SQS queue for messages first. Each message contains hyperparameter ranges in message body. The Lambda function creates HPO jobs only if HPO job limit is not reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load hpo_lambda.py\n",
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "import uuid\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "role = <'SageMaker execution role ARN'>\n",
    "sess = sagemaker.session.Session()\n",
    "region = sess._region_name\n",
    "bucket = sess.default_bucket()\n",
    "key_prefix = \"hpo-sqs\"\n",
    "\n",
    "#check HPO jobs\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "#sqs client\n",
    "sqs = boto3.client('sqs')\n",
    "queue_url = <'queue_url'>\n",
    "\n",
    "HPO_LIMIT = 100\n",
    "\n",
    "\n",
    "def check_hpo_jobs():\n",
    "    response = sm_client.list_hyper_parameter_tuning_jobs(\n",
    "    MaxResults=HPO_LIMIT,\n",
    "    StatusEquals='InProgress')\n",
    "    return len(list(response[\"HyperParameterTuningJobSummaries\"]))\n",
    "\n",
    "\n",
    "def create_hpo(container,train_input,validation_input,hp_range):\n",
    "    print(hp_range)\n",
    "\n",
    "    hyperparameter_ranges = {'gamma': ContinuousParameter(hp_range['gamma_lb'], hp_range['gamma_ub']),\n",
    "        'alpha': ContinuousParameter(0, 2),\n",
    "        'lambda': ContinuousParameter(0, 2)}\n",
    "    hyperparameters={\n",
    "        \"num_round\":\"100\",\n",
    "        \"early_stopping_rounds\":\"9\",\n",
    "        \"max_depth\": \"5\",\n",
    "        \"subsample\": \"0.9\",\n",
    "        \"silent\": \"0\",\n",
    "        \"objective\": \"binary:logistic\",\n",
    "    }\n",
    "    objective_metric_name = 'validation:f1'\n",
    "    xgb_churn = Estimator(\n",
    "            role=role,\n",
    "            image_uri=container,\n",
    "            base_job_name=\"xgboost-churn\",\n",
    "            instance_count=1,\n",
    "            instance_type=\"ml.m5.xlarge\",\n",
    "            hyperparameters=hyperparameters\n",
    "    )\n",
    "\n",
    "    tuner = HyperparameterTuner(xgb_churn,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            base_tuning_job_name = 'xgb-churn-hpo'+str(uuid.uuid4())[:3],\n",
    "                            max_jobs=15,\n",
    "                            max_parallel_jobs=5)\n",
    "    tuner.fit({\"train\": train_input, \"validation\": validation_input}, wait=False)\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "\n",
    "    #fist: check HPO jobs in progress\n",
    "    hpo_in_progress = check_hpo_jobs()\n",
    "\n",
    "    if hpo_in_progress>=HPO_LIMIT:\n",
    "        return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps('HPO running full')\n",
    "    }\n",
    "    else:\n",
    "        hpo_capacity = HPO_LIMIT - hpo_in_progress\n",
    "        container = image_uris.retrieve(\"xgboost\", region, \"0.90-2\")\n",
    "        train_input = TrainingInput(f\"s3://{bucket}/{key_prefix}/train/train.csv\", content_type=\"text/csv\")\n",
    "        validation_input = TrainingInput(f\"s3://{bucket}/{key_prefix}/validation/validation.csv\", content_type=\"text/csv\")\n",
    "\n",
    "        while hpo_capacity> 0:\n",
    "            sqs_response = sqs.receive_message(QueueUrl = queue_url)\n",
    "            if 'Messages' in sqs_response.keys():\n",
    "                msgs = sqs_response['Messages']\n",
    "                for msg in msgs:\n",
    "                    try:\n",
    "                        hp_in_msg = json.loads(msg['Body'])['hyperparameter_ranges']\n",
    "                        create_hpo(container,train_input,validation_input,hp_in_msg)\n",
    "                        response = sqs.delete_message(QueueUrl=queue_url,ReceiptHandle=msg['ReceiptHandle'])\n",
    "                        hpo_capacity = hpo_capacity-1\n",
    "                        if hpo_capacity == 0:\n",
    "                            break\n",
    "                    except :\n",
    "                        return (\"error occurred for message {}\".format(msg['Body']))\n",
    "            else:\n",
    "                return {'statusCode': 200, 'body': json.dumps('Queue is empty')}\n",
    "\n",
    "        return {'statusCode': 200,  'body': json.dumps('Lambda completes') }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create Lambda function in AWS management console by copying and paste the code above. Make sure you have the following setup:\n",
    "* Use Python3.7 run time. \n",
    "* Make sure you enter the right `role` ARN and `queue_url` created at setup step in the Lambda function code. \n",
    "* Add both the `sagemakersdk` layer (built from previous step) and `AWSLambda-Python37-SciPy1x` layer to your Lambda function. `AWSLambda-Python37-SciPy1x` layer is provided by AWS. You can add it to your Lambda function as follows:  click `Configuration`,  expand `Designer`,  click `Layers` and then `Add a layer`. In `Choose a layer` section, select `AWS Layers`, and select `AWSLambda-Python37-SciPy1x` from the drop down list. The correct layer setup should look as shown in the figure below.\n",
    "* Set Lambda function `Timeout` to be 15 mins. This is useful when you need to create a large number of HPO jobs in one Lambda function execution. \n",
    "* Set Lambda function `Memory` to be 2048MB or more.\n",
    "* Make sure the execution role of your Lambda function has permission to read from and delete messages from SQS queue and to list SageMaker hyperparameter tuning job summaries as well as to create SageMaker hyperparameter tuning jobs. \n",
    "\n",
    "<img src=\"layers.png\" width = 600, height = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Lambda trigger\n",
    "\n",
    "Click `Add trigger` in your Lambda function `Configuration` page. In the `Trigger configuration` page, select `EventBridge (cloudWatch Events)`, `Create a new rule` and name your `Rule name`. Make sure the `Schedule expression` option is selected, enter `rate(10 minutes)`, and click `Add`. This will trigger our Lambda function every 10 mins. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for testing \n",
    "\n",
    "We use SageMaker session to upload data to S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.session.Session()\n",
    "bucket = sess.default_bucket()\n",
    "key_prefix = \"hpo-sqs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The dataset we use for testing is publicly available and was mentioned in the book [Discovering Knowledge in Data](https://www.amazon.com/dp/0470908742/) by Daniel T. Larose. It is attributed by the author to the University of California Irvine Repository of Machine Learning Datasets.  Let's download and read that dataset in now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://dataminingconsultant.com/DKD2e_data_sets.zip\n",
    "! apt-get install -y unzip\n",
    "!unzip -o DKD2e_data_sets.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = pd.read_csv('./Data sets/churn.txt')\n",
    "churn = churn.drop('Phone', axis=1)\n",
    "churn['Area Code'] = churn['Area Code'].astype(object)\n",
    "churn = churn.drop(['Day Charge', 'Eve Charge', 'Night Charge', 'Intl Charge'], axis=1)\n",
    "model_data = pd.get_dummies(churn)\n",
    "model_data = pd.concat([model_data['Churn?_True.'], model_data.drop(['Churn?_False.', 'Churn?_True.'], axis=1)], axis=1)\n",
    "\n",
    "train_data, validation_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data)), int(0.9 * len(model_data))])\n",
    "\n",
    "\n",
    "sess.upload_string_as_file_body(body=train_data.to_csv(index=False, header=False),bucket=bucket,key=f\"{key_prefix}/train/train.csv\")\n",
    "sess.upload_string_as_file_body(body=validation_data.to_csv(index=False, header=False),bucket=bucket,key=f\"{key_prefix}/validation/validation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to SQS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "sqs = boto3.client('sqs')\n",
    "queue_url = 'https://sqs.us-east-1.amazonaws.com/084313272408/hpo-queue'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our message, we set the lower bound `gamma_lb` and upper bound `gamma_ub` for `gamma`, which is one of the tunable hyperparameters for demonstration purposes. You can expand the body of the message to include more fields such as other hyperparameters. \n",
    "\n",
    "We start by putting 150 messages in to our SQS queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    response = sqs.send_message(\n",
    "    QueueUrl=queue_url,\n",
    "    DelaySeconds=1,\n",
    "    MessageBody=(\n",
    "        '{\"hyperparameter_ranges\":{\"gamma_lb\":0,\"gamma_ub\":2}}'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please keep in mind our Lambda function is triggered every 10 mins. Once our Lambda function is triggered, if you check your `Hyperparameter tuning jobs` from SageMaker console, you should see HPO jobs running. "
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
